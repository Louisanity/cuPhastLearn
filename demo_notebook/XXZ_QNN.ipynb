{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a phase transition in the XXZ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "import qiskit.extensions.quantum_initializer as qeqi\n",
    "import time\n",
    "from scipy.optimize import minimize, approx_fprime\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse.linalg as SPLA\n",
    "import csv\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "#from skopt import gp_minimize\n",
    "#from numba import jit, njit\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Entangler\n",
    "import TensorNetwork\n",
    "import hamiltonians\n",
    "#import TNOptimize\n",
    "import uuid\n",
    "import json\n",
    "import utils\n",
    "\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams.update({'figure.figsize': [9, 6]})\n",
    "plt.rcParams['figure.facecolor'] = 'black'  # For the figure background\n",
    "plt.rcParams['axes.facecolor'] = 'black'    # For the axes background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_qubits = 10\n",
    "wire = list(range(n_qubits))\n",
    "depth = 4\n",
    "depth_classifier = 6\n",
    "\n",
    "ent = Entangler.IsingEntangler()\n",
    "TN = TensorNetwork.Checkerboard(wire, ent, depth=depth)\n",
    "\n",
    "TN_classifier = TensorNetwork.Checkerboard(wire, ent, depth=depth_classifier)\n",
    "\n",
    "\n",
    "tol = 1e-6\n",
    "method = \"L-BFGS-B\"\n",
    "n_max = 100\n",
    "n_cdata = 2**n_qubits\n",
    "sv_b = Aer.get_backend(\"statevector_simulator\")\n",
    "qasm_b = Aer.get_backend(\"qasm_simulator\")\n",
    "unitary_b = Aer.get_backend('unitary_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains the rows where first 1024 entries are the wavefunction, next 100 are the parameters, then the Jz parameter, energy, and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_data = \"vqe_2024-02-20_21-09-05.csv\"#\"vqe_2024-02-19_12-29-18.csv\"\n",
    "#bigger_data = \"vqe_2024-02-18_18-50-31.csv\"\n",
    "#gpu_data = \"vqe_GPU_2019-05-28_13-28-07.csv\"\n",
    "filename = small_data\n",
    "\n",
    "\n",
    "df_vqe_2 = pd.read_csv(filename, header=None)\n",
    "df_vqe_2 = df_vqe_2.applymap(lambda x: complex(x))\n",
    "\n",
    "df_vqe_2[n_max] = df_vqe_2[n_max].apply(lambda x: x.real)\n",
    "df_vqe_2[n_max+1] = df_vqe_2[n_max+1].apply(lambda x: x.real)\n",
    "df_vqe_2[n_max+2] = df_vqe_2[n_max+2].apply(lambda x: x.real)\n",
    "\n",
    "# df_vqe = df_vqe_2.drop([0, 1])\n",
    "df_vqe = df_vqe_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 103)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(df_vqe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      100        101\n",
      "0   0.000 -12.441273\n",
      "1   0.000 -12.437664\n",
      "2   0.002 -12.445168\n",
      "3   0.002 -12.455932\n",
      "4   0.004 -12.463515\n",
      "5   0.004 -12.452688\n",
      "6   0.006 -12.471078\n",
      "7   0.006 -12.460173\n",
      "8   0.008 -12.467764\n",
      "9   0.008 -12.478683\n",
      "10  0.010 -12.475092\n",
      "11  0.010 -12.486232\n",
      "12  0.012 -12.482860\n",
      "13  0.012 -12.493690\n",
      "14  0.014 -12.490424\n",
      "15  0.014 -12.501336\n",
      "16  0.016 -12.497897\n",
      "17  0.016 -12.508893\n",
      "18  0.018 -12.516301\n",
      "19  0.018 -12.505564\n",
      "[1, 2, 5, 7, 8, 10, 12, 14, 16, 19]\n",
      "[0, 3, 4, 6, 9, 11, 13, 15, 17, 18]\n",
      "=============\n",
      "      100        101\n",
      "0   0.000 -12.441273\n",
      "3   0.002 -12.455932\n",
      "4   0.004 -12.463515\n",
      "6   0.006 -12.471078\n",
      "9   0.008 -12.478683\n",
      "11  0.010 -12.486232\n",
      "13  0.012 -12.493690\n",
      "15  0.014 -12.501336\n",
      "17  0.016 -12.508893\n",
      "18  0.018 -12.516301\n"
     ]
    }
   ],
   "source": [
    "df_vqe_clean = df_vqe.sort_values(by=[n_max])\n",
    "df_vqe_clean.index = np.arange(len(df_vqe))\n",
    "# df_vqe_clean = df_vqe.sort_index(by=[n_max])\n",
    "\n",
    "todrop = []\n",
    "tokeep = []\n",
    "for i in range(len(df_vqe) // 2):\n",
    "    E_1 = df_vqe_clean.iloc[i * 2, n_max + 1]\n",
    "    E_2 = df_vqe_clean.iloc[i * 2 + 1, n_max + 1]\n",
    "    h_1 = df_vqe_clean.iloc[i * 2, n_max]\n",
    "    h_2 = df_vqe_clean.iloc[i * 2 + 1, n_max]\n",
    "#     print(h_1, h_2)\n",
    "#     print(E_1, E_2)\n",
    "#     print(\"====\")\n",
    "    if (E_2 > E_1):\n",
    "        todrop.append(i * 2 + 1)\n",
    "        tokeep.append(i * 2)\n",
    "    else:\n",
    "        todrop.append(i * 2)\n",
    "        tokeep.append(i * 2 + 1)\n",
    "\n",
    "        \n",
    "for i in range(len(df_vqe) // 2):\n",
    "    E_kept = df_vqe_clean.iloc[tokeep[i], n_max + 1]\n",
    "    E_dropped = df_vqe_clean.iloc[todrop[i], n_max + 1]\n",
    "    if E_dropped < E_kept:\n",
    "        print(\"AAA\")\n",
    "\n",
    "print(df_vqe_clean.iloc[:20, [n_max, n_max + 1]])\n",
    "\n",
    "print(todrop[:10])\n",
    "print(tokeep[:10])\n",
    "\n",
    "print(\"=============\")        \n",
    "        \n",
    "df_vqe_clean = df_vqe_clean.drop(todrop)\n",
    "print(df_vqe_clean.iloc[:10, [n_max, n_max + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_vqe_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flips\n",
    "\n",
    "First I am going to flip the spins along the X direction. Then for each of the data points I will also add a random Z rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_flip = df_vqe_clean.copy()\\n# df_flip = df_vqe.copy()\\ndf_flip.index = np.arange(len(df_flip))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_flip = df_vqe_clean.copy()\n",
    "# df_flip = df_vqe.copy()\n",
    "df_flip.index = np.arange(len(df_flip))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## hardcoded for 10 qubits and depth 4\\nz_gate_indices = [74 + i * 5 + k for i in range(5) for k in (4, 5)]\\nx_gate_indices = [74 + i * 5 + k for i in range(5) for k in (1, 2)]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''## hardcoded for 10 qubits and depth 4\n",
    "z_gate_indices = [74 + i * 5 + k for i in range(5) for k in (4, 5)]\n",
    "x_gate_indices = [74 + i * 5 + k for i in range(5) for k in (1, 2)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor n in z_gate_indices:\\n    df_flip[2**n_qubits + n] *= -1\\n\\nfor n in x_gate_indices:\\n    df_flip[2**n_qubits + n] += np.pi\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for n in z_gate_indices:\n",
    "    df_flip[2**n_qubits + n] *= -1\n",
    "\n",
    "for n in x_gate_indices:\n",
    "    df_flip[2**n_qubits + n] += np.pi\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwavefun_cols_order = list(reversed(range(1024)))\\ncols_order = wavefun_cols_order + list(range(1024, n_max + 3))\\ndf_flip = df_flip.reindex(columns=cols_order)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "wavefun_cols_order = list(reversed(range(1024)))\n",
    "cols_order = wavefun_cols_order + list(range(1024, n_max + 3))\n",
    "df_flip = df_flip.reindex(columns=cols_order)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the correctness of the flip operation, I will now check that the wavefunction, ansatz parameters and the energy are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nh_0 = hamiltonians.xxz_heisenberg_model(10, 1, 0)\\nh_1 = hamiltonians.xxz_heisenberg_model(10, 0, 1)\\nH_0 = hamiltonians.explicit_hamiltonian(h_0)\\nH_1 = hamiltonians.explicit_hamiltonian(h_1)\\n\\nenergy_off = False\\nstatebuilding_error = False\\n\\nfor i, row in df_flip.iterrows():\\n#     if i>5:\\n#         break\\n        \\n    state = np.array(row[:2**n_qubits])\\n    E = row[n_max + 1].real\\n    h = row[n_max].real\\n    E_fact = (state.conj() @ (H_0 + h * H_1) @ state).real\\n    if not(np.isclose(E, E_fact)):\\n        print(\"Found energy error in row {}\".format(i))\\n        energy_off = True\\n        \\n    params = np.array(row[2**n_qubits : 2**n_qubits + 100])    \\n    circ = TN.construct_circuit(params)\\n    state_built = utils.get_state(circ)\\n#     print(abs(state_built.conj() @ state))\\n#     print(np.linalg.norm(state))\\n#     print(np.linalg.norm(state_built))\\n#     print(\"====\")\\n    product = abs(state_built.conj() @ state)\\n    if not(np.isclose(product, 1)):\\n        print(\"Found state vs params error in row {}\".format(i))\\n        statebuilding_error = True\\n\\n        \\nif (not energy_off and not statebuilding_error):\\n    print(\"All OK\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "h_0 = hamiltonians.xxz_heisenberg_model(10, 1, 0)\n",
    "h_1 = hamiltonians.xxz_heisenberg_model(10, 0, 1)\n",
    "H_0 = hamiltonians.explicit_hamiltonian(h_0)\n",
    "H_1 = hamiltonians.explicit_hamiltonian(h_1)\n",
    "\n",
    "energy_off = False\n",
    "statebuilding_error = False\n",
    "\n",
    "for i, row in df_flip.iterrows():\n",
    "#     if i>5:\n",
    "#         break\n",
    "        \n",
    "    state = np.array(row[:2**n_qubits])\n",
    "    E = row[n_max + 1].real\n",
    "    h = row[n_max].real\n",
    "    E_fact = (state.conj() @ (H_0 + h * H_1) @ state).real\n",
    "    if not(np.isclose(E, E_fact)):\n",
    "        print(\"Found energy error in row {}\".format(i))\n",
    "        energy_off = True\n",
    "        \n",
    "    params = np.array(row[2**n_qubits : 2**n_qubits + 100])    \n",
    "    circ = TN.construct_circuit(params)\n",
    "    state_built = utils.get_state(circ)\n",
    "#     print(abs(state_built.conj() @ state))\n",
    "#     print(np.linalg.norm(state))\n",
    "#     print(np.linalg.norm(state_built))\n",
    "#     print(\"====\")\n",
    "    product = abs(state_built.conj() @ state)\n",
    "    if not(np.isclose(product, 1)):\n",
    "        print(\"Found state vs params error in row {}\".format(i))\n",
    "        statebuilding_error = True\n",
    "\n",
    "        \n",
    "if (not energy_off and not statebuilding_error):\n",
    "    print(\"All OK\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_with_flip = df_vqe.append(df_flip)\\n# df_with_flip = df_vqe_clean.append(df_flip)\\nlen(df_with_flip)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_with_flip = df_vqe.append(df_flip)\n",
    "# df_with_flip = df_vqe_clean.append(df_flip)\n",
    "len(df_with_flip)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_rotated = df_with_flip.copy()\\ndf_rotated.index = np.arange(len(df_rotated))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_rotated = df_with_flip.copy()\n",
    "df_rotated.index = np.arange(len(df_rotated))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### change the params by adding random angles to params\\n\\nfor i in range(len(df_rotated)):\\n    angle = 2 * np.pi * np.random.rand()\\n    for n in z_gate_indices:\\n        df_rotated.iloc[i, 2**n_qubits + n] += angle\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### change the params by adding random angles to params\n",
    "\n",
    "for i in range(len(df_rotated)):\n",
    "    angle = 2 * np.pi * np.random.rand()\n",
    "    for n in z_gate_indices:\n",
    "        df_rotated.iloc[i, 2**n_qubits + n] += angle\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## construct new states based on the params provided (not a good solution really)\\n\\nfor i in range(len(df_rotated)):\\n    params = np.array(df_rotated.iloc[i, 2**n_qubits:(2**n_qubits + TN.n_params)])\\n    circ = TN.construct_circuit(params)\\n    state_built = utils.get_state(circ)\\n    h = df_rotated.iloc[i, n_max]\\n    E_built = (state_built.conj() @ (H_0 + h * H_1) @ state_built).real\\n    E = df_rotated.iloc[i, n_max + 1]\\n    if not (np.isclose(E, E_built)):\\n        print('Error')\\n    df_rotated.iloc[i, :2**n_qubits] = state_built\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## construct new states based on the params provided (not a good solution really)\n",
    "\n",
    "for i in range(len(df_rotated)):\n",
    "    params = np.array(df_rotated.iloc[i, 2**n_qubits:(2**n_qubits + TN.n_params)])\n",
    "    circ = TN.construct_circuit(params)\n",
    "    state_built = utils.get_state(circ)\n",
    "    h = df_rotated.iloc[i, n_max]\n",
    "    E_built = (state_built.conj() @ (H_0 + h * H_1) @ state_built).real\n",
    "    E = df_rotated.iloc[i, n_max + 1]\n",
    "    if not (np.isclose(E, E_built)):\n",
    "        print('Error')\n",
    "    df_rotated.iloc[i, :2**n_qubits] = state_built\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 150\n",
    "# params = np.array(df_rotated.iloc[i, 2**n_qubits:(2**n_qubits + TN.n_params)])\n",
    "# circ = TN.construct_circuit(params)\n",
    "# state_built = utils.get_state(circ)\n",
    "# E = df_rotated.iloc[i, n_max + 1]\n",
    "# print(E)\n",
    "# h = df_rotated.iloc[i, n_max]\n",
    "# E_built = (state_built.conj() @ (H_0 + h * H_1) @ state_built).real\n",
    "# print(E_built)\n",
    "# state = np.array(df_rotated.iloc[i, :2**n_qubits])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_total = df_with_flip.append(df_rotated)\\ndf_total.index = np.arange(len(df_total))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_total = df_with_flip.append(df_rotated)\n",
    "df_total.index = np.arange(len(df_total))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### Save the total database just in case\\n\\ndf_total.to_csv(path_or_buf=\"df_total_bigger.csv\", index=False, header=None)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#### Save the total database just in case\n",
    "\n",
    "df_total.to_csv(path_or_buf=\"df_total_bigger.csv\", index=False, header=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf = df_total.copy()\\nlen(df_total)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = df_total.copy()\n",
    "len(df_total)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the prepared dataset if you don't want to build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "### Load if necessary\n",
    "\n",
    "#df_total = pd.read_csv(\"df_total_bigger.csv\", header=None)\n",
    "df_total = df_vqe_clean\n",
    "#df_total[n_max+2] = df_total[n_max+2].apply(lambda x: x*2-1) # transfer label to {-1,1}\n",
    "print(len(df_total))\n",
    "#df_total = df_total.applymap(lambda x: np.complex(x))\n",
    "\n",
    "#df_total[n_max] = df_total[n_max].apply(lambda x: x.real)\n",
    "#df_total[n_max+1] = df_total[n_max+1].apply(lambda x: x.real)\n",
    "#df_total[n_max+2] = df_total[n_max+2].apply(lambda x: x.real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_shuffled = df_total.sample(frac=1).reset_index(drop=True)\n",
    "train_pos = int(0.8 * len(df_total))\n",
    "test_pos = int(1 * len(df_total))\n",
    "df_train = df_shuffled.iloc[:train_pos,:]\n",
    "df_test = df_shuffled.iloc[train_pos:test_pos,:]\n",
    "\n",
    "df_train_data = np.array(df_train[:-3]) # will cut of the last 3 elements in circuit\n",
    "df_train_label = np.array(df_train[n_max+2])\n",
    "df_test_data = np.array(df_test[:-3]) # will cut of the last 3 elements in circuit\n",
    "df_test_label = np.array(df_test[n_max+2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cuda == True:\n",
    "    dev = qml.device(\"lightning.gpu\",wire)\n",
    "else:\n",
    "    dev = qml.device(\"default.qubit\",wire)\n",
    "    \n",
    "@qml.qnode(dev)\n",
    "def circuit(params, weights):\n",
    "    TN.construct_circuit(params) # build the ground state, embed the train data\n",
    "    TN_classifier.construct_circuit(weights)\n",
    "    return qml.expval(qml.PauliZ(0)@qml.PauliZ(1)@qml.PauliZ(2)@qml.PauliZ(3)@qml.PauliZ(4)@qml.PauliZ(5)@qml.PauliZ(6)@qml.PauliZ(7)@qml.PauliZ(8)@qml.PauliZ(9))\n",
    "    \n",
    "def variational_classifier(weights, bias, params):\n",
    "    return circuit(params[:n_max], weights) + bias\n",
    "\n",
    "def loss_fn(labels, predictions):\n",
    "    return sum((labels - predictions)**2)/len(labels)\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "def cost(weights, bias, train_data, labels):\n",
    "    predictions = [variational_classifier(weights, bias, params) for params in train_data]\n",
    "    return loss_fn(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the QNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Additional torch-related imports\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.nn import NLLLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 3\n",
    "NUM_SHOTS = 3000\n",
    "SHIFT = np.pi/4\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '010', '011', '100', '101', '110']\n"
     ]
    }
   ],
   "source": [
    "# create list of all possible outputs of quantum circuit (2**NUM_QUBITS possible)\n",
    "import itertools\n",
    "def create_QC_OUTPUTS():\n",
    "    measurements = list(itertools.product([0, 1], repeat=NUM_QUBITS))\n",
    "    return [''.join([str(bit) for bit in measurement]) for measurement in measurements]\n",
    "\n",
    "QC_OUTPUTS = create_QC_OUTPUTS()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuCircuit():\n",
    "    def __init__(self, n_qubits, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.n_qubits = n_qubits\n",
    "        self.shots = shots        \n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots):\n",
    "        expects = np.zeros(len(QC_OUTPUTS))\n",
    "        for k in range(len(QC_OUTPUTS)):\n",
    "            key = QC_OUTPUTS[k]\n",
    "            perc = counts.get(key, 0) /shots\n",
    "            expects[k] = perc\n",
    "        return expects\n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "        self.dev = qml.device(\"default.qubit\",wires=self.n_qubits, shots=self.shots)\n",
    "            \n",
    "        @qml.qnode(self.dev)\n",
    "        def NNcircuit(params):\n",
    "            for idx in range(self.n_qubits):\n",
    "                qml.Hadamard(wires=idx)\n",
    "                qml.RY(params[idx], wires=idx)\n",
    "            #qml.CNOT([0, 1])\n",
    "            #qml.CNOT([1, 2])\n",
    "            return qml.counts()\n",
    "        counts = NNcircuit(params=params)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QuCirc'):\n",
    "            ctx.QuCirc = QuCircuit(NUM_QUBITS, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QuCirc.run(i)\n",
    "        result = torch.tensor(exp_value)\n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        _, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(NUM_QUBITS):\n",
    "            shift_right = input_numbers.detach().clone()\n",
    "            shift_right[k] = shift_right[k] + SHIFT\n",
    "            shift_left = input_numbers.detach().clone()\n",
    "            shift_left[k] = shift_left[k] - SHIFT\n",
    "            \n",
    "#             print('shift_right = {}, shift_left = {}'.format(shift_right, shift_left))\n",
    "            \n",
    "            expectation_right = ctx.QuCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QuCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right, expectation_left))\n",
    "            gradient = torch.tensor(expectation_right - expectation_left).float()\n",
    "            # rescale gradient\n",
    "#             gradient = gradient / torch.norm(gradient)\n",
    "#             print('gradient for k={}: {}'.format(k, gradient))\n",
    "            gradients = torch.cat((gradients, gradient.unsqueeze(0)))\n",
    "            \n",
    "        result = torch.Tensor(gradients)\n",
    "#         print('gradients = {}'.format(result))\n",
    "#         print('grad_output = {}'.format(grad_output))\n",
    "\n",
    "        return (result.float() * grad_output.float()).T    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5118], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "NUM_QUBITS = 3\n",
    "qc = TorchCircuit.apply\n",
    "\n",
    "class NewNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 30, kernel_size=100, stride=100)\n",
    "        self.conv2 = nn.Conv1d(2, 4, kernel_size=5, stride=4,padding=1)\n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=8, stride=5,padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=1)\n",
    "        self.fc1 = nn.Linear(8, 4)\n",
    "        self.fc2 = nn.Linear(4, 2)\n",
    "        self.fc3 = nn.Linear(30, NUM_QUBITS)\n",
    "        self.fc4 = nn.Linear(7, 1)\n",
    "        self.bn = nn.BatchNorm1d(4)\n",
    "        self.qc = TorchCircuit.apply\n",
    "        self.qcsim = nn.Linear(NUM_QUBITS, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0).unsqueeze(0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        MODE = 'QC'\n",
    "    \n",
    "        if MODE == 'QC': \n",
    "            x = qc(x[0]).float()\n",
    "        else:\n",
    "            x = self.qcsim(x)\n",
    "        x = torch.sigmoid(self.fc4(x)).float()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pred = self.forward(x)\n",
    "        return pred > 0.5\n",
    "\n",
    "# define input tensor\n",
    "input_tensor = torch.tensor([random.random() for _ in range(100)]).float()#torch.rand(1127, requires_grad=True).float()\n",
    "\n",
    "# instantiate the model\n",
    "model = NewNet()\n",
    "\n",
    "# pass input tensor through the model\n",
    "output = model(input_tensor)\n",
    "\n",
    "# print output tensor\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/2s70_qgs7_16ts4sn_34n01w0000gn/T/ipykernel_74235/2335723218.py:19: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Copy.cpp:299.)\n",
      "  data = torch.tensor(df_train_data[i], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [10%]\tLoss: 0.5297\tAccuracy: 90.97%\n",
      "Training [20%]\tLoss: 0.3880\tAccuracy: 97.99%\n",
      "Training [30%]\tLoss: 0.3077\tAccuracy: 98.24%\n",
      "Training [40%]\tLoss: 0.2421\tAccuracy: 97.87%\n",
      "Training [50%]\tLoss: 0.2028\tAccuracy: 97.87%\n",
      "Training [60%]\tLoss: 0.1725\tAccuracy: 97.99%\n",
      "Training [70%]\tLoss: 0.1608\tAccuracy: 97.87%\n",
      "Training [80%]\tLoss: 0.1372\tAccuracy: 97.99%\n",
      "Training [90%]\tLoss: 0.1219\tAccuracy: 98.37%\n",
      "Training [100%]\tLoss: 0.1106\tAccuracy: 97.99%\n"
     ]
    }
   ],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "network = NewNet()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "network.train()  # Set model to training mode\n",
    "epochs = 10\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for i in range(len(df_train_data)):\n",
    "        # Get the current input and target\n",
    "        data = torch.tensor(df_train_data[i], dtype=torch.float32)\n",
    "        target = torch.tensor(df_train_label[i], dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output.squeeze(), target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predicted = output.data > 0.5\n",
    "        total_correct += (predicted == target).sum().item()\n",
    "        \n",
    "    loss_list.append(total_loss / len(df_train_data))\n",
    "    acc_list.append(total_correct / len(df_train_data))\n",
    "    \n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}\\tAccuracy: {:.2%}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1], acc_list[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data is : 196/197 = 99.49238586425781%\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "accuracy = 0\n",
    "number = 0\n",
    "for i in range(len(df_test_data)):\n",
    "    data = Tensor(df_test_data[i])\n",
    "    target = Tensor(df_test_label).long()  # convert target to LongTensor\n",
    "    number +=1\n",
    "    output = network.predict(data)\n",
    "    accuracy += (output == target[i].item())*1\n",
    "accuracy = accuracy[0]\n",
    "\n",
    "print(\"Performance on test data is : {}/{} = {}%\".format(accuracy,number,100*accuracy/number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
