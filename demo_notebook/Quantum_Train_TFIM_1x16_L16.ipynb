{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import code block \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchquantum as tq\n",
    "import time \n",
    " \n",
    "# import quantum_datasets as qd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A Matter of Taste challenge :  \n",
    "### Building a phase identification classifier of the quantum many-body system. \n",
    "#### with \n",
    "\n",
    "## *Quantum-Train*:   \n",
    "### Rethinking Hybrid Quantum-Classical Machine Learning in the Model Compression Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of this notebook are sorted in the following manner:  \n",
    "1. Generate the training data and testing data from the PennyLane quantum dataset. \n",
    "2. Construct a Phase identification classifier by Pytorch, pure classically. \n",
    "3. Introduce the Quantum-Train (QT) concept, to train the same classical NN by a QNN and Mapping model, with polylog parameter reduction.\n",
    "4. The QT part of the code is contructed by TorchQuantum, the training and testing result will be shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the training data and testing data from the PennyLane quantum dataset. \n",
    "\n",
    "<img src=\"images/phase_classifier.png\" width=\"1000px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Ising chain data set\n",
    "Ising_chain_data_set = qml.data.load(\"qspin\", sysname=\"Ising\", periodicity=\"full\", lattice=\"chain\", layout=[\"1x16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the classical shadow measurement result and the corresponding basis into the single matrix, \n",
    "## where 25 samples are picked in each data. \n",
    "\n",
    "dataset_shadow_meas_and_basis = [] \n",
    "for h_value in range(100):\n",
    "    for slice_ in range(40):\n",
    "        sample_per_slice = 25\n",
    "        dataset_shadow_meas_and_basis.append(\n",
    "            \n",
    "            torch.cat(\n",
    "            (\n",
    "                torch.tensor(Ising_chain_data_set[0].shadow_meas[h_value][sample_per_slice*slice_:sample_per_slice*(slice_+1)]),\n",
    "                torch.tensor(Ising_chain_data_set[0].shadow_basis[h_value][sample_per_slice*slice_:sample_per_slice*(slice_+1)]),\n",
    "                # torch.full((sample_per_slice,), Ising_chain_data_set[0].parameters['h'][h_value]).unsqueeze(1)\n",
    "\n",
    "            ),\n",
    "            dim = 1).unsqueeze(0).float()\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_shadow_meas_and_basis[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the label data, here we use the phase label as the target of the classifcation task. \n",
    "\n",
    "dataset_order_parameter = [] \n",
    "for h_value_index in range(100):\n",
    "    for slice_ in range(40):\n",
    "        dataset_order_parameter.append(\n",
    "            #torch.tensor(Ising_chain_data_set[0].parameters['h'][h_value_index]).float()\n",
    "            torch.tensor((1/8)*Ising_chain_data_set[0].order_params[h_value_index]).float()\n",
    "        )\n",
    "        \n",
    "dataset_phase_label = [] \n",
    "for h_value_index in range(100):\n",
    "    for slice_ in range(40):\n",
    "        h = Ising_chain_data_set[0].parameters['h'][h_value_index]\n",
    "        if h < 1:\n",
    "            dataset_phase_label.append(0)\n",
    "        elif h >= 1:\n",
    "            dataset_phase_label.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function to generate the dataset that will be recognized by Pytorch\n",
    "\n",
    "\n",
    "class MatrixDataset(Dataset):\n",
    "    \"\"\"Matrix and label dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, matrices, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            matrices (list of numpy.ndarray or torch.Tensor): List of matrices.\n",
    "            labels (list of int): List of labels corresponding to each matrix.\n",
    "        \"\"\"\n",
    "        self.matrices = matrices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        matrix = self.matrices[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert to torch.Tensor if not already\n",
    "        if not isinstance(matrix, torch.Tensor):\n",
    "            matrix = torch.tensor(matrix, dtype=torch.float32)\n",
    "\n",
    "        if not isinstance(label, torch.Tensor):\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return matrix, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = MatrixDataset(dataset_shadow_meas_and_basis, dataset_order_parameter)\n",
    "dataset = MatrixDataset(dataset_shadow_meas_and_basis, dataset_phase_label)\n",
    "\n",
    "\n",
    "## split the data for testing and training \n",
    "\n",
    "# Assuming 'dataset' is your initialized dataset\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% for training\n",
    "test_size = dataset_size - train_size  # 20% for testing\n",
    "\n",
    "# Calculate the interval for selecting test indices in the interleaved pattern\n",
    "# The +1 ensures that we round up, preventing the train set from being too small\n",
    "interval = int(dataset_size / test_size) + 1\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    if i % interval == 0:\n",
    "        test_indices.append(i)\n",
    "    else:\n",
    "        train_indices.append(i)\n",
    "\n",
    "# Adjust the sizes in case of rounding issues\n",
    "while len(train_indices) > train_size:\n",
    "    # Move excess from train to test to maintain the size constraint\n",
    "    train_indices, test_indices = train_indices[:-1], test_indices + [train_indices[-1]]\n",
    "\n",
    "while len(test_indices) > test_size:\n",
    "    # Move excess from test to train if necessary\n",
    "    test_indices, train_indices = test_indices[:-1], train_indices + [test_indices[-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Phase identification classifier by Pytorch, pure classically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [100/160], Loss: 0.3478\n",
      "Epoch [2/25], Step [100/160], Loss: 0.4905\n",
      "Epoch [3/25], Step [100/160], Loss: 0.4299\n",
      "Epoch [4/25], Step [100/160], Loss: 0.1669\n",
      "Epoch [5/25], Step [100/160], Loss: 0.0974\n",
      "Epoch [6/25], Step [100/160], Loss: 0.0290\n",
      "Epoch [7/25], Step [100/160], Loss: 0.1927\n",
      "Epoch [8/25], Step [100/160], Loss: 0.0782\n",
      "Epoch [9/25], Step [100/160], Loss: 0.1330\n",
      "Epoch [10/25], Step [100/160], Loss: 0.0084\n",
      "Epoch [11/25], Step [100/160], Loss: 0.0484\n",
      "Epoch [12/25], Step [100/160], Loss: 0.0187\n",
      "Epoch [13/25], Step [100/160], Loss: 0.1157\n",
      "Epoch [14/25], Step [100/160], Loss: 0.0537\n",
      "Epoch [15/25], Step [100/160], Loss: 0.0028\n",
      "Epoch [16/25], Step [100/160], Loss: 0.0109\n",
      "Epoch [17/25], Step [100/160], Loss: 0.0013\n",
      "Epoch [18/25], Step [100/160], Loss: 0.0000\n",
      "Epoch [19/25], Step [100/160], Loss: 0.0010\n",
      "Epoch [20/25], Step [100/160], Loss: 0.0005\n",
      "Epoch [21/25], Step [100/160], Loss: 0.0004\n",
      "Epoch [22/25], Step [100/160], Loss: 0.0004\n",
      "Epoch [23/25], Step [100/160], Loss: 0.0003\n",
      "Epoch [24/25], Step [100/160], Loss: 0.0002\n",
      "Epoch [25/25], Step [100/160], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "### model initialization ###\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 25\n",
    "\n",
    "\n",
    "# Define the CNN model (Phase identification classifier)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)  # 1st conv layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Pooling layer\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)  # 2nd conv layer\n",
    "        self.fc1 = nn.Linear(5 * 3 * 12, 200)  \n",
    "        self.fc2 = nn.Linear(200, 2)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 100.00%\n",
      "Accuracy on the test set: 87.12%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum-Train (QT) concept could be summarized into the graph \n",
    "<img src=\"images/training_flow.png\" width=\"1000px\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first, we estimate how many qubits are required for the above Phase identification classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  39222\n",
      "Required qubit number:  16\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class LewHybridNN(nn.Module):\n",
    "    class QLayer(nn.Module):\n",
    "        def __init__(self, n_blocks):\n",
    "            super().__init__()\n",
    "            self.n_wires = int(np.ceil(np.log2(len(nw_list_normal)))),\n",
    "            self.n_wires = self.n_wires[0]\n",
    "            self.n_blocks = n_blocks\n",
    "            self.u3_layers = tq.QuantumModuleList()\n",
    "            self.cu3_layers = tq.QuantumModuleList()\n",
    "            # self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "            for _ in range(self.n_blocks):\n",
    "                self.u3_layers.append(\n",
    "                    tq.Op1QAllLayer(\n",
    "                        op=tq.U3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                    )\n",
    "                )\n",
    "                self.cu3_layers.append(\n",
    "                    tq.Op2QAllLayer(\n",
    "                        op=tq.CU3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                        circular=True,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "        def forward(self):\n",
    "            qdev = tq.QuantumDevice(\n",
    "                n_wires=self.n_wires, bsz=1, device=next(self.parameters()).device\n",
    "            )\n",
    "            easy_scale_coeff = 2**(n_qubit-1)\n",
    "            gamma = 0.1\n",
    "            beta  = 0.8\n",
    "            alpha = 0.3\n",
    "            for k in range(self.n_blocks):\n",
    "                self.u3_layers[k](qdev)\n",
    "                self.cu3_layers[k](qdev)\n",
    "                \n",
    "            state_mag = qdev.get_states_1d().abs()[0] \n",
    "            state_mag = state_mag[:len(nw_list_normal)]\n",
    "            x = torch.abs(state_mag) ** 2\n",
    "            # x = torch.log(x)\n",
    "            x = x.reshape(len(nw_list_normal),1)\n",
    "            x = (beta*torch.tanh(gamma*easy_scale_coeff*x))**(alpha) \n",
    "            x = x - torch.mean(x)\n",
    "            x.to(device)\n",
    "            return x\n",
    "\n",
    "        \n",
    "        \n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            return output\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.MappingNetwork = self.MappingModel(n_qubit+1, [10, 20, 10], 1).to(device)  \n",
    "        # self.MappingNetwork = self.ConvMappingModel()\n",
    "        self.QuantumNN = self.QLayer(q_depth).to(device)   #arch={\"n_blocks\": q_depth})\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        probs_ = self.QuantumNN()\n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        ## Now we have generated the classical NN weights by a QNN + MM model with polylog number of parameters ! \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  621\n",
      "# of trainable parameter in QNN model:  1536\n",
      "# of trainable parameter in full model:  2157\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "\n",
    "step = 1e-4                 # Learning rate\n",
    "batch_size = 100       # Number of samples for each training step\n",
    "num_epochs = 50             # Number of training epochs\n",
    "q_depth = 16             # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "model = LewHybridNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, verbose = True, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.MappingModel(n_qubit+1,  [10, 20, 10], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params - num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/32], Loss: 0.4160, batch time: 0.88, accuracy:  83.00%\n",
      "Epoch [1/50], Step [2/32], Loss: 0.5923, batch time: 0.74, accuracy:  69.00%\n",
      "Epoch [1/50], Step [3/32], Loss: 0.4451, batch time: 0.69, accuracy:  80.00%\n",
      "Epoch [1/50], Step [4/32], Loss: 0.4153, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [1/50], Step [5/32], Loss: 0.3924, batch time: 0.70, accuracy:  87.00%\n",
      "Epoch [1/50], Step [6/32], Loss: 0.4112, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [1/50], Step [7/32], Loss: 0.4679, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [1/50], Step [8/32], Loss: 0.4396, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [1/50], Step [9/32], Loss: 0.3563, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [1/50], Step [10/32], Loss: 0.3475, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [1/50], Step [11/32], Loss: 0.4655, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [1/50], Step [12/32], Loss: 0.3758, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [1/50], Step [13/32], Loss: 0.4043, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [1/50], Step [14/32], Loss: 0.4934, batch time: 0.64, accuracy:  77.00%\n",
      "Epoch [1/50], Step [15/32], Loss: 0.3369, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [1/50], Step [16/32], Loss: 0.3749, batch time: 0.66, accuracy:  86.00%\n",
      "Epoch [1/50], Step [17/32], Loss: 0.3685, batch time: 0.59, accuracy:  87.00%\n",
      "Epoch [1/50], Step [18/32], Loss: 0.3538, batch time: 0.59, accuracy:  87.00%\n",
      "Epoch [1/50], Step [19/32], Loss: 0.4861, batch time: 0.59, accuracy:  82.00%\n",
      "Epoch [1/50], Step [20/32], Loss: 0.3446, batch time: 0.73, accuracy:  86.00%\n",
      "Epoch [1/50], Step [21/32], Loss: 0.4073, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [1/50], Step [22/32], Loss: 0.3414, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [1/50], Step [23/32], Loss: 0.3914, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [1/50], Step [24/32], Loss: 0.4005, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [1/50], Step [25/32], Loss: 0.3825, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [1/50], Step [26/32], Loss: 0.3756, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [1/50], Step [27/32], Loss: 0.4356, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [1/50], Step [28/32], Loss: 0.4762, batch time: 0.72, accuracy:  80.00%\n",
      "Epoch [1/50], Step [29/32], Loss: 0.4467, batch time: 0.60, accuracy:  77.00%\n",
      "Epoch [1/50], Step [30/32], Loss: 0.3745, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [1/50], Step [31/32], Loss: 0.4579, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [1/50], Step [32/32], Loss: 0.4853, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [2/50], Step [1/32], Loss: 0.3880, batch time: 0.63, accuracy:  80.00%\n",
      "Epoch [2/50], Step [2/32], Loss: 0.4414, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [2/50], Step [3/32], Loss: 0.3379, batch time: 0.65, accuracy:  89.00%\n",
      "Epoch [2/50], Step [4/32], Loss: 0.4266, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [2/50], Step [5/32], Loss: 0.4753, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [2/50], Step [6/32], Loss: 0.4536, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [2/50], Step [7/32], Loss: 0.4682, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [2/50], Step [8/32], Loss: 0.4075, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [2/50], Step [9/32], Loss: 0.4666, batch time: 0.61, accuracy:  80.00%\n",
      "Epoch [2/50], Step [10/32], Loss: 0.3173, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [2/50], Step [11/32], Loss: 0.4359, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [2/50], Step [12/32], Loss: 0.5626, batch time: 0.59, accuracy:  75.00%\n",
      "Epoch [2/50], Step [13/32], Loss: 0.3764, batch time: 0.60, accuracy:  87.00%\n",
      "Epoch [2/50], Step [14/32], Loss: 0.3552, batch time: 0.60, accuracy:  89.00%\n",
      "Epoch [2/50], Step [15/32], Loss: 0.5643, batch time: 0.60, accuracy:  74.00%\n",
      "Epoch [2/50], Step [16/32], Loss: 0.4497, batch time: 0.65, accuracy:  77.00%\n",
      "Epoch [2/50], Step [17/32], Loss: 0.3602, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [2/50], Step [18/32], Loss: 0.6133, batch time: 0.64, accuracy:  74.00%\n",
      "Epoch [2/50], Step [19/32], Loss: 0.4870, batch time: 0.59, accuracy:  74.00%\n",
      "Epoch [2/50], Step [20/32], Loss: 0.3426, batch time: 0.66, accuracy:  87.00%\n",
      "Epoch [2/50], Step [21/32], Loss: 0.3863, batch time: 0.64, accuracy:  86.00%\n",
      "Epoch [2/50], Step [22/32], Loss: 0.3424, batch time: 0.62, accuracy:  88.00%\n",
      "Epoch [2/50], Step [23/32], Loss: 0.4904, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [2/50], Step [24/32], Loss: 0.4223, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [2/50], Step [25/32], Loss: 0.3437, batch time: 0.59, accuracy:  89.00%\n",
      "Epoch [2/50], Step [26/32], Loss: 0.3806, batch time: 0.61, accuracy:  86.00%\n",
      "Epoch [2/50], Step [27/32], Loss: 0.3770, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [2/50], Step [28/32], Loss: 0.3821, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [2/50], Step [29/32], Loss: 0.3625, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [2/50], Step [30/32], Loss: 0.3647, batch time: 0.84, accuracy:  85.00%\n",
      "Epoch [2/50], Step [31/32], Loss: 0.4427, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [2/50], Step [32/32], Loss: 0.5390, batch time: 0.63, accuracy:  79.00%\n",
      "Epoch [3/50], Step [1/32], Loss: 0.4251, batch time: 0.62, accuracy:  78.00%\n",
      "Epoch [3/50], Step [2/32], Loss: 0.3592, batch time: 0.67, accuracy:  86.00%\n",
      "Epoch [3/50], Step [3/32], Loss: 0.4705, batch time: 0.59, accuracy:  78.00%\n",
      "Epoch [3/50], Step [4/32], Loss: 0.4232, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [3/50], Step [5/32], Loss: 0.3810, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [3/50], Step [6/32], Loss: 0.4073, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [3/50], Step [7/32], Loss: 0.4345, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [3/50], Step [8/32], Loss: 0.4124, batch time: 0.59, accuracy:  78.00%\n",
      "Epoch [3/50], Step [9/32], Loss: 0.3931, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [3/50], Step [10/32], Loss: 0.3925, batch time: 0.59, accuracy:  82.00%\n",
      "Epoch [3/50], Step [11/32], Loss: 0.3545, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [3/50], Step [12/32], Loss: 0.4146, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [3/50], Step [13/32], Loss: 0.4973, batch time: 0.61, accuracy:  73.00%\n",
      "Epoch [3/50], Step [14/32], Loss: 0.3320, batch time: 0.62, accuracy:  87.00%\n",
      "Epoch [3/50], Step [15/32], Loss: 0.4808, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [3/50], Step [16/32], Loss: 0.4800, batch time: 0.64, accuracy:  78.00%\n",
      "Epoch [3/50], Step [17/32], Loss: 0.3132, batch time: 0.64, accuracy:  88.00%\n",
      "Epoch [3/50], Step [18/32], Loss: 0.3916, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [3/50], Step [19/32], Loss: 0.3313, batch time: 0.64, accuracy:  91.00%\n",
      "Epoch [3/50], Step [20/32], Loss: 0.4183, batch time: 0.58, accuracy:  83.00%\n",
      "Epoch [3/50], Step [21/32], Loss: 0.4635, batch time: 0.66, accuracy:  74.00%\n",
      "Epoch [3/50], Step [22/32], Loss: 0.6000, batch time: 0.59, accuracy:  74.00%\n",
      "Epoch [3/50], Step [23/32], Loss: 0.3860, batch time: 0.73, accuracy:  82.00%\n",
      "Epoch [3/50], Step [24/32], Loss: 0.4923, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [3/50], Step [25/32], Loss: 0.4219, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [3/50], Step [26/32], Loss: 0.4096, batch time: 0.73, accuracy:  86.00%\n",
      "Epoch [3/50], Step [27/32], Loss: 0.3732, batch time: 0.66, accuracy:  82.00%\n",
      "Epoch [3/50], Step [28/32], Loss: 0.3443, batch time: 0.68, accuracy:  87.00%\n",
      "Epoch [3/50], Step [29/32], Loss: 0.3876, batch time: 0.64, accuracy:  86.00%\n",
      "Epoch [3/50], Step [30/32], Loss: 0.3990, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [3/50], Step [31/32], Loss: 0.4818, batch time: 0.70, accuracy:  83.00%\n",
      "Epoch [3/50], Step [32/32], Loss: 0.5182, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [4/50], Step [1/32], Loss: 0.5110, batch time: 0.70, accuracy:  81.00%\n",
      "Epoch [4/50], Step [2/32], Loss: 0.4175, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [4/50], Step [3/32], Loss: 0.4940, batch time: 0.63, accuracy:  77.00%\n",
      "Epoch [4/50], Step [4/32], Loss: 0.4918, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [4/50], Step [5/32], Loss: 0.5340, batch time: 0.61, accuracy:  74.00%\n",
      "Epoch [4/50], Step [6/32], Loss: 0.4733, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [4/50], Step [7/32], Loss: 0.3012, batch time: 0.78, accuracy:  92.00%\n",
      "Epoch [4/50], Step [8/32], Loss: 0.3723, batch time: 0.68, accuracy:  87.00%\n",
      "Epoch [4/50], Step [9/32], Loss: 0.4614, batch time: 0.68, accuracy:  77.00%\n",
      "Epoch [4/50], Step [10/32], Loss: 0.4927, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [4/50], Step [11/32], Loss: 0.3747, batch time: 0.59, accuracy:  80.00%\n",
      "Epoch [4/50], Step [12/32], Loss: 0.4809, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [4/50], Step [13/32], Loss: 0.3746, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [4/50], Step [14/32], Loss: 0.3247, batch time: 0.59, accuracy:  89.00%\n",
      "Epoch [4/50], Step [15/32], Loss: 0.4033, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [4/50], Step [16/32], Loss: 0.4436, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [4/50], Step [17/32], Loss: 0.3921, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [4/50], Step [18/32], Loss: 0.3190, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [4/50], Step [19/32], Loss: 0.3706, batch time: 0.65, accuracy:  82.00%\n",
      "Epoch [4/50], Step [20/32], Loss: 0.3355, batch time: 0.66, accuracy:  87.00%\n",
      "Epoch [4/50], Step [21/32], Loss: 0.3847, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [4/50], Step [22/32], Loss: 0.3813, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [4/50], Step [23/32], Loss: 0.4831, batch time: 0.64, accuracy:  76.00%\n",
      "Epoch [4/50], Step [24/32], Loss: 0.3547, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [4/50], Step [25/32], Loss: 0.4065, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [4/50], Step [26/32], Loss: 0.3772, batch time: 0.58, accuracy:  84.00%\n",
      "Epoch [4/50], Step [27/32], Loss: 0.4124, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [4/50], Step [28/32], Loss: 0.4720, batch time: 0.59, accuracy:  77.00%\n",
      "Epoch [4/50], Step [29/32], Loss: 0.5506, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [4/50], Step [30/32], Loss: 0.4337, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [4/50], Step [31/32], Loss: 0.3668, batch time: 0.76, accuracy:  84.00%\n",
      "Epoch [4/50], Step [32/32], Loss: 0.4235, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [5/50], Step [1/32], Loss: 0.3577, batch time: 0.59, accuracy:  87.00%\n",
      "Epoch [5/50], Step [2/32], Loss: 0.4026, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [5/50], Step [3/32], Loss: 0.4742, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [5/50], Step [4/32], Loss: 0.3500, batch time: 0.59, accuracy:  83.00%\n",
      "Epoch [5/50], Step [5/32], Loss: 0.4537, batch time: 0.66, accuracy:  82.00%\n",
      "Epoch [5/50], Step [6/32], Loss: 0.4365, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [5/50], Step [7/32], Loss: 0.4548, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [5/50], Step [8/32], Loss: 0.3108, batch time: 0.65, accuracy:  91.00%\n",
      "Epoch [5/50], Step [9/32], Loss: 0.3397, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [5/50], Step [10/32], Loss: 0.3832, batch time: 0.59, accuracy:  81.00%\n",
      "Epoch [5/50], Step [11/32], Loss: 0.4637, batch time: 0.61, accuracy:  76.00%\n",
      "Epoch [5/50], Step [12/32], Loss: 0.4074, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [5/50], Step [13/32], Loss: 0.4060, batch time: 0.58, accuracy:  85.00%\n",
      "Epoch [5/50], Step [14/32], Loss: 0.5155, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [5/50], Step [15/32], Loss: 0.3710, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [5/50], Step [16/32], Loss: 0.4297, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [5/50], Step [17/32], Loss: 0.3871, batch time: 0.66, accuracy:  84.00%\n",
      "Epoch [5/50], Step [18/32], Loss: 0.4854, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [5/50], Step [19/32], Loss: 0.3383, batch time: 0.68, accuracy:  86.00%\n",
      "Epoch [5/50], Step [20/32], Loss: 0.5175, batch time: 0.59, accuracy:  77.00%\n",
      "Epoch [5/50], Step [21/32], Loss: 0.4574, batch time: 0.60, accuracy:  77.00%\n",
      "Epoch [5/50], Step [22/32], Loss: 0.3825, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [5/50], Step [23/32], Loss: 0.5097, batch time: 0.66, accuracy:  75.00%\n",
      "Epoch [5/50], Step [24/32], Loss: 0.4625, batch time: 0.65, accuracy:  81.00%\n",
      "Epoch [5/50], Step [25/32], Loss: 0.4888, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [5/50], Step [26/32], Loss: 0.4145, batch time: 0.59, accuracy:  83.00%\n",
      "Epoch [5/50], Step [27/32], Loss: 0.3556, batch time: 0.59, accuracy:  87.00%\n",
      "Epoch [5/50], Step [28/32], Loss: 0.3533, batch time: 0.71, accuracy:  87.00%\n",
      "Epoch [5/50], Step [29/32], Loss: 0.3382, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [5/50], Step [30/32], Loss: 0.4280, batch time: 0.59, accuracy:  82.00%\n",
      "Epoch [5/50], Step [31/32], Loss: 0.3706, batch time: 0.67, accuracy:  83.00%\n",
      "Epoch [5/50], Step [32/32], Loss: 0.4039, batch time: 0.64, accuracy:  82.00%\n",
      "Epoch [6/50], Step [1/32], Loss: 0.5037, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [6/50], Step [2/32], Loss: 0.4269, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [6/50], Step [3/32], Loss: 0.3430, batch time: 0.61, accuracy:  87.00%\n",
      "Epoch [6/50], Step [4/32], Loss: 0.4331, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [6/50], Step [5/32], Loss: 0.4535, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [6/50], Step [6/32], Loss: 0.3795, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [6/50], Step [7/32], Loss: 0.4362, batch time: 0.64, accuracy:  79.00%\n",
      "Epoch [6/50], Step [8/32], Loss: 0.3944, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [6/50], Step [9/32], Loss: 0.4375, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [6/50], Step [10/32], Loss: 0.4211, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [6/50], Step [11/32], Loss: 0.3721, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [6/50], Step [12/32], Loss: 0.3859, batch time: 0.70, accuracy:  84.00%\n",
      "Epoch [6/50], Step [13/32], Loss: 0.3085, batch time: 0.61, accuracy:  87.00%\n",
      "Epoch [6/50], Step [14/32], Loss: 0.4164, batch time: 0.59, accuracy:  81.00%\n",
      "Epoch [6/50], Step [15/32], Loss: 0.4810, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [6/50], Step [16/32], Loss: 0.4774, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [6/50], Step [17/32], Loss: 0.4651, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [6/50], Step [18/32], Loss: 0.4164, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [6/50], Step [19/32], Loss: 0.4763, batch time: 0.68, accuracy:  77.00%\n",
      "Epoch [6/50], Step [20/32], Loss: 0.3584, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [6/50], Step [21/32], Loss: 0.3910, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [6/50], Step [22/32], Loss: 0.4170, batch time: 0.65, accuracy:  82.00%\n",
      "Epoch [6/50], Step [23/32], Loss: 0.4049, batch time: 0.59, accuracy:  85.00%\n",
      "Epoch [6/50], Step [24/32], Loss: 0.3772, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [6/50], Step [25/32], Loss: 0.5014, batch time: 0.70, accuracy:  77.00%\n",
      "Epoch [6/50], Step [26/32], Loss: 0.4469, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [6/50], Step [27/32], Loss: 0.4086, batch time: 0.64, accuracy:  79.00%\n",
      "Epoch [6/50], Step [28/32], Loss: 0.4395, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [6/50], Step [29/32], Loss: 0.3884, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [6/50], Step [30/32], Loss: 0.3353, batch time: 0.70, accuracy:  86.00%\n",
      "Epoch [6/50], Step [31/32], Loss: 0.4044, batch time: 0.74, accuracy:  80.00%\n",
      "Epoch [6/50], Step [32/32], Loss: 0.4501, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [7/50], Step [1/32], Loss: 0.4370, batch time: 0.65, accuracy:  81.00%\n",
      "Epoch [7/50], Step [2/32], Loss: 0.3659, batch time: 0.65, accuracy:  86.00%\n",
      "Epoch [7/50], Step [3/32], Loss: 0.4187, batch time: 0.66, accuracy:  81.00%\n",
      "Epoch [7/50], Step [4/32], Loss: 0.4908, batch time: 0.70, accuracy:  79.00%\n",
      "Epoch [7/50], Step [5/32], Loss: 0.4085, batch time: 0.73, accuracy:  82.00%\n",
      "Epoch [7/50], Step [6/32], Loss: 0.4632, batch time: 0.66, accuracy:  80.00%\n",
      "Epoch [7/50], Step [7/32], Loss: 0.3960, batch time: 0.71, accuracy:  84.00%\n",
      "Epoch [7/50], Step [8/32], Loss: 0.4302, batch time: 0.64, accuracy:  78.00%\n",
      "Epoch [7/50], Step [9/32], Loss: 0.3649, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [7/50], Step [10/32], Loss: 0.3890, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [7/50], Step [11/32], Loss: 0.3546, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [7/50], Step [12/32], Loss: 0.3628, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [7/50], Step [13/32], Loss: 0.3574, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [7/50], Step [14/32], Loss: 0.3904, batch time: 0.62, accuracy:  87.00%\n",
      "Epoch [7/50], Step [15/32], Loss: 0.3749, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [7/50], Step [16/32], Loss: 0.3654, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [7/50], Step [17/32], Loss: 0.4453, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [7/50], Step [18/32], Loss: 0.4639, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [7/50], Step [19/32], Loss: 0.3907, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [7/50], Step [20/32], Loss: 0.4599, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [7/50], Step [21/32], Loss: 0.4225, batch time: 0.67, accuracy:  79.00%\n",
      "Epoch [7/50], Step [22/32], Loss: 0.3812, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [7/50], Step [23/32], Loss: 0.3791, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [7/50], Step [24/32], Loss: 0.4718, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [7/50], Step [25/32], Loss: 0.5107, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [7/50], Step [26/32], Loss: 0.3638, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [7/50], Step [27/32], Loss: 0.4913, batch time: 0.61, accuracy:  74.00%\n",
      "Epoch [7/50], Step [28/32], Loss: 0.4811, batch time: 0.59, accuracy:  80.00%\n",
      "Epoch [7/50], Step [29/32], Loss: 0.4087, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [7/50], Step [30/32], Loss: 0.4230, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [7/50], Step [31/32], Loss: 0.4970, batch time: 0.65, accuracy:  75.00%\n",
      "Epoch [7/50], Step [32/32], Loss: 0.3612, batch time: 0.64, accuracy:  90.00%\n",
      "Epoch [8/50], Step [1/32], Loss: 0.4117, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [8/50], Step [2/32], Loss: 0.3838, batch time: 0.67, accuracy:  86.00%\n",
      "Epoch [8/50], Step [3/32], Loss: 0.3802, batch time: 0.71, accuracy:  83.00%\n",
      "Epoch [8/50], Step [4/32], Loss: 0.4236, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [8/50], Step [5/32], Loss: 0.3389, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [8/50], Step [6/32], Loss: 0.4903, batch time: 0.66, accuracy:  80.00%\n",
      "Epoch [8/50], Step [7/32], Loss: 0.4718, batch time: 0.68, accuracy:  80.00%\n",
      "Epoch [8/50], Step [8/32], Loss: 0.4875, batch time: 0.59, accuracy:  78.00%\n",
      "Epoch [8/50], Step [9/32], Loss: 0.4534, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [8/50], Step [10/32], Loss: 0.4003, batch time: 0.59, accuracy:  82.00%\n",
      "Epoch [8/50], Step [11/32], Loss: 0.3725, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [8/50], Step [12/32], Loss: 0.4326, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [8/50], Step [13/32], Loss: 0.3705, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [8/50], Step [14/32], Loss: 0.5382, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [8/50], Step [15/32], Loss: 0.4278, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [8/50], Step [16/32], Loss: 0.3946, batch time: 0.74, accuracy:  81.00%\n",
      "Epoch [8/50], Step [17/32], Loss: 0.4345, batch time: 0.61, accuracy:  80.00%\n",
      "Epoch [8/50], Step [18/32], Loss: 0.4834, batch time: 0.61, accuracy:  80.00%\n",
      "Epoch [8/50], Step [19/32], Loss: 0.4644, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [8/50], Step [20/32], Loss: 0.3627, batch time: 0.66, accuracy:  85.00%\n",
      "Epoch [8/50], Step [21/32], Loss: 0.3408, batch time: 0.63, accuracy:  88.00%\n",
      "Epoch [8/50], Step [22/32], Loss: 0.4308, batch time: 0.64, accuracy:  79.00%\n",
      "Epoch [8/50], Step [23/32], Loss: 0.4473, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [8/50], Step [24/32], Loss: 0.2803, batch time: 0.62, accuracy:  89.00%\n",
      "Epoch [8/50], Step [25/32], Loss: 0.3782, batch time: 0.69, accuracy:  80.00%\n",
      "Epoch [8/50], Step [26/32], Loss: 0.4251, batch time: 0.74, accuracy:  81.00%\n",
      "Epoch [8/50], Step [27/32], Loss: 0.4649, batch time: 0.66, accuracy:  82.00%\n",
      "Epoch [8/50], Step [28/32], Loss: 0.3729, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [8/50], Step [29/32], Loss: 0.3922, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [8/50], Step [30/32], Loss: 0.5335, batch time: 0.68, accuracy:  74.00%\n",
      "Epoch [8/50], Step [31/32], Loss: 0.4292, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [8/50], Step [32/32], Loss: 0.3821, batch time: 0.66, accuracy:  88.00%\n",
      "Epoch [9/50], Step [1/32], Loss: 0.4541, batch time: 0.78, accuracy:  78.00%\n",
      "Epoch [9/50], Step [2/32], Loss: 0.4012, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [9/50], Step [3/32], Loss: 0.4574, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [9/50], Step [4/32], Loss: 0.4260, batch time: 0.62, accuracy:  75.00%\n",
      "Epoch [9/50], Step [5/32], Loss: 0.4449, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [9/50], Step [6/32], Loss: 0.3063, batch time: 0.59, accuracy:  87.00%\n",
      "Epoch [9/50], Step [7/32], Loss: 0.4226, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [9/50], Step [8/32], Loss: 0.3356, batch time: 0.60, accuracy:  88.00%\n",
      "Epoch [9/50], Step [9/32], Loss: 0.4321, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [9/50], Step [10/32], Loss: 0.4072, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [9/50], Step [11/32], Loss: 0.2935, batch time: 0.65, accuracy:  92.00%\n",
      "Epoch [9/50], Step [12/32], Loss: 0.3646, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [9/50], Step [13/32], Loss: 0.3819, batch time: 0.60, accuracy:  86.00%\n",
      "Epoch [9/50], Step [14/32], Loss: 0.4355, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [9/50], Step [15/32], Loss: 0.3097, batch time: 0.69, accuracy:  87.00%\n",
      "Epoch [9/50], Step [16/32], Loss: 0.4507, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [9/50], Step [17/32], Loss: 0.4408, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [9/50], Step [18/32], Loss: 0.3261, batch time: 0.68, accuracy:  88.00%\n",
      "Epoch [9/50], Step [19/32], Loss: 0.4607, batch time: 0.65, accuracy:  82.00%\n",
      "Epoch [9/50], Step [20/32], Loss: 0.4430, batch time: 0.63, accuracy:  76.00%\n",
      "Epoch [9/50], Step [21/32], Loss: 0.5088, batch time: 0.64, accuracy:  78.00%\n",
      "Epoch [9/50], Step [22/32], Loss: 0.3961, batch time: 0.62, accuracy:  78.00%\n",
      "Epoch [9/50], Step [23/32], Loss: 0.4786, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [9/50], Step [24/32], Loss: 0.4029, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [9/50], Step [25/32], Loss: 0.3520, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [9/50], Step [26/32], Loss: 0.4078, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [9/50], Step [27/32], Loss: 0.4468, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [9/50], Step [28/32], Loss: 0.4732, batch time: 0.67, accuracy:  85.00%\n",
      "Epoch [9/50], Step [29/32], Loss: 0.4090, batch time: 0.68, accuracy:  81.00%\n",
      "Epoch [9/50], Step [30/32], Loss: 0.4488, batch time: 0.73, accuracy:  82.00%\n",
      "Epoch [9/50], Step [31/32], Loss: 0.4419, batch time: 0.83, accuracy:  80.00%\n",
      "Epoch [9/50], Step [32/32], Loss: 0.3855, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [10/50], Step [1/32], Loss: 0.3640, batch time: 0.69, accuracy:  90.00%\n",
      "Epoch [10/50], Step [2/32], Loss: 0.5011, batch time: 0.68, accuracy:  80.00%\n",
      "Epoch [10/50], Step [3/32], Loss: 0.4250, batch time: 0.73, accuracy:  79.00%\n",
      "Epoch [10/50], Step [4/32], Loss: 0.5123, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [10/50], Step [5/32], Loss: 0.4032, batch time: 0.67, accuracy:  81.00%\n",
      "Epoch [10/50], Step [6/32], Loss: 0.4133, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [10/50], Step [7/32], Loss: 0.3847, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [10/50], Step [8/32], Loss: 0.3526, batch time: 0.68, accuracy:  86.00%\n",
      "Epoch [10/50], Step [9/32], Loss: 0.5660, batch time: 0.65, accuracy:  74.00%\n",
      "Epoch [10/50], Step [10/32], Loss: 0.3489, batch time: 0.58, accuracy:  84.00%\n",
      "Epoch [10/50], Step [11/32], Loss: 0.3928, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [10/50], Step [12/32], Loss: 0.3679, batch time: 0.60, accuracy:  86.00%\n",
      "Epoch [10/50], Step [13/32], Loss: 0.4755, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [10/50], Step [14/32], Loss: 0.3662, batch time: 0.61, accuracy:  89.00%\n",
      "Epoch [10/50], Step [15/32], Loss: 0.3928, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [10/50], Step [16/32], Loss: 0.3219, batch time: 0.59, accuracy:  88.00%\n",
      "Epoch [10/50], Step [17/32], Loss: 0.3712, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [10/50], Step [18/32], Loss: 0.3397, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [10/50], Step [19/32], Loss: 0.4862, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [10/50], Step [20/32], Loss: 0.3616, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [10/50], Step [21/32], Loss: 0.5316, batch time: 0.62, accuracy:  75.00%\n",
      "Epoch [10/50], Step [22/32], Loss: 0.4477, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [10/50], Step [23/32], Loss: 0.3842, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [10/50], Step [24/32], Loss: 0.4282, batch time: 0.64, accuracy:  86.00%\n",
      "Epoch [10/50], Step [25/32], Loss: 0.4112, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [10/50], Step [26/32], Loss: 0.4430, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [10/50], Step [27/32], Loss: 0.4159, batch time: 0.58, accuracy:  83.00%\n",
      "Epoch [10/50], Step [28/32], Loss: 0.3744, batch time: 0.64, accuracy:  86.00%\n",
      "Epoch [10/50], Step [29/32], Loss: 0.5077, batch time: 0.64, accuracy:  77.00%\n",
      "Epoch [10/50], Step [30/32], Loss: 0.3421, batch time: 0.67, accuracy:  87.00%\n",
      "Epoch [10/50], Step [31/32], Loss: 0.3643, batch time: 0.60, accuracy:  86.00%\n",
      "Epoch [10/50], Step [32/32], Loss: 0.3531, batch time: 0.68, accuracy:  86.00%\n",
      "Epoch [11/50], Step [1/32], Loss: 0.3907, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [11/50], Step [2/32], Loss: 0.3903, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [11/50], Step [3/32], Loss: 0.3740, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [11/50], Step [4/32], Loss: 0.3814, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [11/50], Step [5/32], Loss: 0.4381, batch time: 0.64, accuracy:  79.00%\n",
      "Epoch [11/50], Step [6/32], Loss: 0.4382, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [11/50], Step [7/32], Loss: 0.5542, batch time: 0.64, accuracy:  78.00%\n",
      "Epoch [11/50], Step [8/32], Loss: 0.3595, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [11/50], Step [9/32], Loss: 0.3730, batch time: 0.74, accuracy:  87.00%\n",
      "Epoch [11/50], Step [10/32], Loss: 0.4784, batch time: 0.80, accuracy:  77.00%\n",
      "Epoch [11/50], Step [11/32], Loss: 0.4108, batch time: 1.22, accuracy:  82.00%\n",
      "Epoch [11/50], Step [12/32], Loss: 0.4044, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [11/50], Step [13/32], Loss: 0.3999, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [11/50], Step [14/32], Loss: 0.3523, batch time: 0.70, accuracy:  88.00%\n",
      "Epoch [11/50], Step [15/32], Loss: 0.4625, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [11/50], Step [16/32], Loss: 0.3568, batch time: 0.61, accuracy:  86.00%\n",
      "Epoch [11/50], Step [17/32], Loss: 0.4021, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [11/50], Step [18/32], Loss: 0.4322, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [11/50], Step [19/32], Loss: 0.4062, batch time: 0.59, accuracy:  77.00%\n",
      "Epoch [11/50], Step [20/32], Loss: 0.4369, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [11/50], Step [21/32], Loss: 0.3876, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [11/50], Step [22/32], Loss: 0.4102, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [11/50], Step [23/32], Loss: 0.4862, batch time: 0.69, accuracy:  79.00%\n",
      "Epoch [11/50], Step [24/32], Loss: 0.4548, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [11/50], Step [25/32], Loss: 0.3931, batch time: 0.77, accuracy:  83.00%\n",
      "Epoch [11/50], Step [26/32], Loss: 0.4440, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [11/50], Step [27/32], Loss: 0.3758, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [11/50], Step [28/32], Loss: 0.3976, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [11/50], Step [29/32], Loss: 0.3719, batch time: 0.66, accuracy:  86.00%\n",
      "Epoch [11/50], Step [30/32], Loss: 0.3857, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [11/50], Step [31/32], Loss: 0.4774, batch time: 0.59, accuracy:  79.00%\n",
      "Epoch [11/50], Step [32/32], Loss: 0.4009, batch time: 0.70, accuracy:  85.00%\n",
      "Epoch [12/50], Step [1/32], Loss: 0.3378, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [12/50], Step [2/32], Loss: 0.3648, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [12/50], Step [3/32], Loss: 0.4027, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [12/50], Step [4/32], Loss: 0.3739, batch time: 0.69, accuracy:  86.00%\n",
      "Epoch [12/50], Step [5/32], Loss: 0.3866, batch time: 0.62, accuracy:  87.00%\n",
      "Epoch [12/50], Step [6/32], Loss: 0.4296, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [12/50], Step [7/32], Loss: 0.3054, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [12/50], Step [8/32], Loss: 0.4555, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [12/50], Step [9/32], Loss: 0.4745, batch time: 0.67, accuracy:  81.00%\n",
      "Epoch [12/50], Step [10/32], Loss: 0.3689, batch time: 0.70, accuracy:  83.00%\n",
      "Epoch [12/50], Step [11/32], Loss: 0.4815, batch time: 0.67, accuracy:  78.00%\n",
      "Epoch [12/50], Step [12/32], Loss: 0.4557, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [12/50], Step [13/32], Loss: 0.4636, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [12/50], Step [14/32], Loss: 0.4532, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [12/50], Step [15/32], Loss: 0.3289, batch time: 0.65, accuracy:  88.00%\n",
      "Epoch [12/50], Step [16/32], Loss: 0.4577, batch time: 0.64, accuracy:  76.00%\n",
      "Epoch [12/50], Step [17/32], Loss: 0.3932, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [12/50], Step [18/32], Loss: 0.4235, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [12/50], Step [19/32], Loss: 0.4259, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [12/50], Step [20/32], Loss: 0.4985, batch time: 0.63, accuracy:  77.00%\n",
      "Epoch [12/50], Step [21/32], Loss: 0.4239, batch time: 0.66, accuracy:  81.00%\n",
      "Epoch [12/50], Step [22/32], Loss: 0.4752, batch time: 0.67, accuracy:  81.00%\n",
      "Epoch [12/50], Step [23/32], Loss: 0.3799, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [12/50], Step [24/32], Loss: 0.3376, batch time: 0.68, accuracy:  87.00%\n",
      "Epoch [12/50], Step [25/32], Loss: 0.4826, batch time: 0.69, accuracy:  73.00%\n",
      "Epoch [12/50], Step [26/32], Loss: 0.4239, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [12/50], Step [27/32], Loss: 0.4665, batch time: 0.72, accuracy:  81.00%\n",
      "Epoch [12/50], Step [28/32], Loss: 0.3995, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [12/50], Step [29/32], Loss: 0.3601, batch time: 0.64, accuracy:  85.00%\n",
      "Epoch [12/50], Step [30/32], Loss: 0.3893, batch time: 0.67, accuracy:  86.00%\n",
      "Epoch [12/50], Step [31/32], Loss: 0.4141, batch time: 0.67, accuracy:  81.00%\n",
      "Epoch [12/50], Step [32/32], Loss: 0.4137, batch time: 0.68, accuracy:  86.00%\n",
      "Epoch [13/50], Step [1/32], Loss: 0.3687, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [13/50], Step [2/32], Loss: 0.4379, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [13/50], Step [3/32], Loss: 0.3679, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [13/50], Step [4/32], Loss: 0.4220, batch time: 0.72, accuracy:  85.00%\n",
      "Epoch [13/50], Step [5/32], Loss: 0.4026, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [13/50], Step [6/32], Loss: 0.5087, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [13/50], Step [7/32], Loss: 0.3127, batch time: 0.63, accuracy:  90.00%\n",
      "Epoch [13/50], Step [8/32], Loss: 0.4181, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [13/50], Step [9/32], Loss: 0.4258, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [13/50], Step [10/32], Loss: 0.4047, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [13/50], Step [11/32], Loss: 0.3753, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [13/50], Step [12/32], Loss: 0.4000, batch time: 0.70, accuracy:  81.00%\n",
      "Epoch [13/50], Step [13/32], Loss: 0.4536, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [13/50], Step [14/32], Loss: 0.4667, batch time: 0.64, accuracy:  72.00%\n",
      "Epoch [13/50], Step [15/32], Loss: 0.3520, batch time: 0.66, accuracy:  81.00%\n",
      "Epoch [13/50], Step [16/32], Loss: 0.4845, batch time: 0.68, accuracy:  76.00%\n",
      "Epoch [13/50], Step [17/32], Loss: 0.4841, batch time: 0.72, accuracy:  81.00%\n",
      "Epoch [13/50], Step [18/32], Loss: 0.5298, batch time: 0.71, accuracy:  76.00%\n",
      "Epoch [13/50], Step [19/32], Loss: 0.4073, batch time: 0.65, accuracy:  86.00%\n",
      "Epoch [13/50], Step [20/32], Loss: 0.5075, batch time: 0.69, accuracy:  76.00%\n",
      "Epoch [13/50], Step [21/32], Loss: 0.4264, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [13/50], Step [22/32], Loss: 0.3170, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [13/50], Step [23/32], Loss: 0.3746, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [13/50], Step [24/32], Loss: 0.3649, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [13/50], Step [25/32], Loss: 0.3444, batch time: 0.71, accuracy:  86.00%\n",
      "Epoch [13/50], Step [26/32], Loss: 0.3780, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [13/50], Step [27/32], Loss: 0.3471, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [13/50], Step [28/32], Loss: 0.3553, batch time: 0.64, accuracy:  86.00%\n",
      "Epoch [13/50], Step [29/32], Loss: 0.4671, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [13/50], Step [30/32], Loss: 0.4141, batch time: 0.59, accuracy:  80.00%\n",
      "Epoch [13/50], Step [31/32], Loss: 0.4065, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [13/50], Step [32/32], Loss: 0.4317, batch time: 0.59, accuracy:  83.00%\n",
      "Epoch [14/50], Step [1/32], Loss: 0.3936, batch time: 0.59, accuracy:  83.00%\n",
      "Epoch [14/50], Step [2/32], Loss: 0.5342, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [14/50], Step [3/32], Loss: 0.3507, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [14/50], Step [4/32], Loss: 0.3911, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [14/50], Step [5/32], Loss: 0.5250, batch time: 0.60, accuracy:  77.00%\n",
      "Epoch [14/50], Step [6/32], Loss: 0.3346, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [14/50], Step [7/32], Loss: 0.4669, batch time: 0.73, accuracy:  76.00%\n",
      "Epoch [14/50], Step [8/32], Loss: 0.4700, batch time: 0.72, accuracy:  81.00%\n",
      "Epoch [14/50], Step [9/32], Loss: 0.5213, batch time: 0.69, accuracy:  74.00%\n",
      "Epoch [14/50], Step [10/32], Loss: 0.3456, batch time: 1.08, accuracy:  86.00%\n",
      "Epoch [14/50], Step [11/32], Loss: 0.4601, batch time: 0.67, accuracy:  85.00%\n",
      "Epoch [14/50], Step [12/32], Loss: 0.3805, batch time: 0.67, accuracy:  89.00%\n",
      "Epoch [14/50], Step [13/32], Loss: 0.4162, batch time: 0.67, accuracy:  82.00%\n",
      "Epoch [14/50], Step [14/32], Loss: 0.4336, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [14/50], Step [15/32], Loss: 0.4203, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [14/50], Step [16/32], Loss: 0.4334, batch time: 0.69, accuracy:  85.00%\n",
      "Epoch [14/50], Step [17/32], Loss: 0.4874, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [14/50], Step [18/32], Loss: 0.4465, batch time: 0.67, accuracy:  78.00%\n",
      "Epoch [14/50], Step [19/32], Loss: 0.3060, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [14/50], Step [20/32], Loss: 0.4460, batch time: 0.68, accuracy:  80.00%\n",
      "Epoch [14/50], Step [21/32], Loss: 0.3882, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [14/50], Step [22/32], Loss: 0.3232, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [14/50], Step [23/32], Loss: 0.4074, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [14/50], Step [24/32], Loss: 0.2732, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [14/50], Step [25/32], Loss: 0.4051, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [14/50], Step [26/32], Loss: 0.3916, batch time: 0.68, accuracy:  81.00%\n",
      "Epoch [14/50], Step [27/32], Loss: 0.4399, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [14/50], Step [28/32], Loss: 0.4249, batch time: 0.66, accuracy:  80.00%\n",
      "Epoch [14/50], Step [29/32], Loss: 0.3674, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [14/50], Step [30/32], Loss: 0.3753, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [14/50], Step [31/32], Loss: 0.4849, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [14/50], Step [32/32], Loss: 0.3984, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [15/50], Step [1/32], Loss: 0.4797, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [15/50], Step [2/32], Loss: 0.3939, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [15/50], Step [3/32], Loss: 0.5333, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [15/50], Step [4/32], Loss: 0.4315, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [15/50], Step [5/32], Loss: 0.3832, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [15/50], Step [6/32], Loss: 0.4448, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [15/50], Step [7/32], Loss: 0.4955, batch time: 0.64, accuracy:  78.00%\n",
      "Epoch [15/50], Step [8/32], Loss: 0.3842, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [15/50], Step [9/32], Loss: 0.4227, batch time: 0.75, accuracy:  82.00%\n",
      "Epoch [15/50], Step [10/32], Loss: 0.3029, batch time: 0.80, accuracy:  88.00%\n",
      "Epoch [15/50], Step [11/32], Loss: 0.4309, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [15/50], Step [12/32], Loss: 0.4200, batch time: 0.63, accuracy:  79.00%\n",
      "Epoch [15/50], Step [13/32], Loss: 0.4501, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [15/50], Step [14/32], Loss: 0.2957, batch time: 0.64, accuracy:  90.00%\n",
      "Epoch [15/50], Step [15/32], Loss: 0.3646, batch time: 0.66, accuracy:  82.00%\n",
      "Epoch [15/50], Step [16/32], Loss: 0.4374, batch time: 0.59, accuracy:  78.00%\n",
      "Epoch [15/50], Step [17/32], Loss: 0.3368, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [15/50], Step [18/32], Loss: 0.4230, batch time: 0.65, accuracy:  82.00%\n",
      "Epoch [15/50], Step [19/32], Loss: 0.4689, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [15/50], Step [20/32], Loss: 0.3409, batch time: 0.71, accuracy:  84.00%\n",
      "Epoch [15/50], Step [21/32], Loss: 0.4616, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [15/50], Step [22/32], Loss: 0.3873, batch time: 0.61, accuracy:  86.00%\n",
      "Epoch [15/50], Step [23/32], Loss: 0.3035, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [15/50], Step [24/32], Loss: 0.4145, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [15/50], Step [25/32], Loss: 0.4470, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [15/50], Step [26/32], Loss: 0.4470, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [15/50], Step [27/32], Loss: 0.3999, batch time: 0.72, accuracy:  86.00%\n",
      "Epoch [15/50], Step [28/32], Loss: 0.4193, batch time: 0.70, accuracy:  80.00%\n",
      "Epoch [15/50], Step [29/32], Loss: 0.4616, batch time: 0.67, accuracy:  77.00%\n",
      "Epoch [15/50], Step [30/32], Loss: 0.4335, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [15/50], Step [31/32], Loss: 0.3655, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [15/50], Step [32/32], Loss: 0.3490, batch time: 0.68, accuracy:  84.00%\n",
      "Epoch [16/50], Step [1/32], Loss: 0.4196, batch time: 0.72, accuracy:  83.00%\n",
      "Epoch [16/50], Step [2/32], Loss: 0.5431, batch time: 1.12, accuracy:  75.00%\n",
      "Epoch [16/50], Step [3/32], Loss: 0.4238, batch time: 0.68, accuracy:  83.00%\n",
      "Epoch [16/50], Step [4/32], Loss: 0.3750, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [16/50], Step [5/32], Loss: 0.4460, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [16/50], Step [6/32], Loss: 0.4150, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [16/50], Step [7/32], Loss: 0.3570, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [16/50], Step [8/32], Loss: 0.4019, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [16/50], Step [9/32], Loss: 0.4030, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [16/50], Step [10/32], Loss: 0.4363, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [16/50], Step [11/32], Loss: 0.3675, batch time: 0.59, accuracy:  83.00%\n",
      "Epoch [16/50], Step [12/32], Loss: 0.3409, batch time: 0.63, accuracy:  88.00%\n",
      "Epoch [16/50], Step [13/32], Loss: 0.6056, batch time: 0.60, accuracy:  77.00%\n",
      "Epoch [16/50], Step [14/32], Loss: 0.4243, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [16/50], Step [15/32], Loss: 0.3765, batch time: 0.67, accuracy:  86.00%\n",
      "Epoch [16/50], Step [16/32], Loss: 0.4506, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [16/50], Step [17/32], Loss: 0.4156, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [16/50], Step [18/32], Loss: 0.4721, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [16/50], Step [19/32], Loss: 0.3941, batch time: 0.68, accuracy:  88.00%\n",
      "Epoch [16/50], Step [20/32], Loss: 0.4168, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [16/50], Step [21/32], Loss: 0.2761, batch time: 0.68, accuracy:  91.00%\n",
      "Epoch [16/50], Step [22/32], Loss: 0.2977, batch time: 0.65, accuracy:  92.00%\n",
      "Epoch [16/50], Step [23/32], Loss: 0.5492, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [16/50], Step [24/32], Loss: 0.4965, batch time: 0.63, accuracy:  79.00%\n",
      "Epoch [16/50], Step [25/32], Loss: 0.5029, batch time: 0.64, accuracy:  79.00%\n",
      "Epoch [16/50], Step [26/32], Loss: 0.3659, batch time: 0.67, accuracy:  85.00%\n",
      "Epoch [16/50], Step [27/32], Loss: 0.4356, batch time: 0.76, accuracy:  82.00%\n",
      "Epoch [16/50], Step [28/32], Loss: 0.3867, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [16/50], Step [29/32], Loss: 0.4215, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [16/50], Step [30/32], Loss: 0.4373, batch time: 0.77, accuracy:  78.00%\n",
      "Epoch [16/50], Step [31/32], Loss: 0.4097, batch time: 0.82, accuracy:  83.00%\n",
      "Epoch [16/50], Step [32/32], Loss: 0.3511, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [17/50], Step [1/32], Loss: 0.3869, batch time: 0.64, accuracy:  82.00%\n",
      "Epoch [17/50], Step [2/32], Loss: 0.3639, batch time: 0.65, accuracy:  88.00%\n",
      "Epoch [17/50], Step [3/32], Loss: 0.3299, batch time: 0.71, accuracy:  90.00%\n",
      "Epoch [17/50], Step [4/32], Loss: 0.4530, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [17/50], Step [5/32], Loss: 0.3297, batch time: 0.75, accuracy:  87.00%\n",
      "Epoch [17/50], Step [6/32], Loss: 0.4601, batch time: 0.70, accuracy:  79.00%\n",
      "Epoch [17/50], Step [7/32], Loss: 0.5077, batch time: 0.64, accuracy:  73.00%\n",
      "Epoch [17/50], Step [8/32], Loss: 0.3262, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [17/50], Step [9/32], Loss: 0.3787, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [17/50], Step [10/32], Loss: 0.4930, batch time: 0.69, accuracy:  80.00%\n",
      "Epoch [17/50], Step [11/32], Loss: 0.4636, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [17/50], Step [12/32], Loss: 0.3932, batch time: 0.67, accuracy:  83.00%\n",
      "Epoch [17/50], Step [13/32], Loss: 0.3715, batch time: 0.67, accuracy:  85.00%\n",
      "Epoch [17/50], Step [14/32], Loss: 0.4643, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [17/50], Step [15/32], Loss: 0.4286, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [17/50], Step [16/32], Loss: 0.3026, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [17/50], Step [17/32], Loss: 0.5153, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [17/50], Step [18/32], Loss: 0.6283, batch time: 0.64, accuracy:  73.00%\n",
      "Epoch [17/50], Step [19/32], Loss: 0.4716, batch time: 0.69, accuracy:  80.00%\n",
      "Epoch [17/50], Step [20/32], Loss: 0.4664, batch time: 0.68, accuracy:  79.00%\n",
      "Epoch [17/50], Step [21/32], Loss: 0.4491, batch time: 0.71, accuracy:  80.00%\n",
      "Epoch [17/50], Step [22/32], Loss: 0.5400, batch time: 0.72, accuracy:  73.00%\n",
      "Epoch [17/50], Step [23/32], Loss: 0.4170, batch time: 0.93, accuracy:  82.00%\n",
      "Epoch [17/50], Step [24/32], Loss: 0.3716, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [17/50], Step [25/32], Loss: 0.3948, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [17/50], Step [26/32], Loss: 0.4492, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [17/50], Step [27/32], Loss: 0.4271, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [17/50], Step [28/32], Loss: 0.3587, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [17/50], Step [29/32], Loss: 0.3470, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [17/50], Step [30/32], Loss: 0.4171, batch time: 0.72, accuracy:  81.00%\n",
      "Epoch [17/50], Step [31/32], Loss: 0.4871, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [17/50], Step [32/32], Loss: 0.3458, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [18/50], Step [1/32], Loss: 0.4110, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [18/50], Step [2/32], Loss: 0.4085, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [18/50], Step [3/32], Loss: 0.4268, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [18/50], Step [4/32], Loss: 0.3973, batch time: 0.70, accuracy:  85.00%\n",
      "Epoch [18/50], Step [5/32], Loss: 0.3326, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [18/50], Step [6/32], Loss: 0.4388, batch time: 0.61, accuracy:  80.00%\n",
      "Epoch [18/50], Step [7/32], Loss: 0.4219, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [18/50], Step [8/32], Loss: 0.4271, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [18/50], Step [9/32], Loss: 0.3928, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [18/50], Step [10/32], Loss: 0.5606, batch time: 0.64, accuracy:  76.00%\n",
      "Epoch [18/50], Step [11/32], Loss: 0.4018, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [18/50], Step [12/32], Loss: 0.4248, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [18/50], Step [13/32], Loss: 0.3284, batch time: 0.66, accuracy:  86.00%\n",
      "Epoch [18/50], Step [14/32], Loss: 0.4388, batch time: 0.63, accuracy:  81.00%\n",
      "Epoch [18/50], Step [15/32], Loss: 0.3279, batch time: 0.69, accuracy:  89.00%\n",
      "Epoch [18/50], Step [16/32], Loss: 0.3696, batch time: 0.69, accuracy:  86.00%\n",
      "Epoch [18/50], Step [17/32], Loss: 0.3639, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [18/50], Step [18/32], Loss: 0.3492, batch time: 0.86, accuracy:  86.00%\n",
      "Epoch [18/50], Step [19/32], Loss: 0.5314, batch time: 0.65, accuracy:  76.00%\n",
      "Epoch [18/50], Step [20/32], Loss: 0.4003, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [18/50], Step [21/32], Loss: 0.4940, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [18/50], Step [22/32], Loss: 0.4439, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [18/50], Step [23/32], Loss: 0.4429, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [18/50], Step [24/32], Loss: 0.4887, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [18/50], Step [25/32], Loss: 0.4615, batch time: 0.64, accuracy:  81.00%\n",
      "Epoch [18/50], Step [26/32], Loss: 0.3728, batch time: 0.67, accuracy:  81.00%\n",
      "Epoch [18/50], Step [27/32], Loss: 0.4552, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [18/50], Step [28/32], Loss: 0.4342, batch time: 0.65, accuracy:  81.00%\n",
      "Epoch [18/50], Step [29/32], Loss: 0.3464, batch time: 0.60, accuracy:  89.00%\n",
      "Epoch [18/50], Step [30/32], Loss: 0.4183, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [18/50], Step [31/32], Loss: 0.4359, batch time: 0.74, accuracy:  82.00%\n",
      "Epoch [18/50], Step [32/32], Loss: 0.3181, batch time: 0.58, accuracy:  87.00%\n",
      "Epoch [19/50], Step [1/32], Loss: 0.4262, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [19/50], Step [2/32], Loss: 0.3965, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [19/50], Step [3/32], Loss: 0.3444, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [19/50], Step [4/32], Loss: 0.4632, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [19/50], Step [5/32], Loss: 0.3560, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [19/50], Step [6/32], Loss: 0.3832, batch time: 0.61, accuracy:  86.00%\n",
      "Epoch [19/50], Step [7/32], Loss: 0.4166, batch time: 0.65, accuracy:  81.00%\n",
      "Epoch [19/50], Step [8/32], Loss: 0.4179, batch time: 0.70, accuracy:  81.00%\n",
      "Epoch [19/50], Step [9/32], Loss: 0.3859, batch time: 1.00, accuracy:  87.00%\n",
      "Epoch [19/50], Step [10/32], Loss: 0.4663, batch time: 0.82, accuracy:  81.00%\n",
      "Epoch [19/50], Step [11/32], Loss: 0.4105, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [19/50], Step [12/32], Loss: 0.4747, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [19/50], Step [13/32], Loss: 0.4014, batch time: 0.60, accuracy:  85.00%\n",
      "Epoch [19/50], Step [14/32], Loss: 0.4139, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [19/50], Step [15/32], Loss: 0.3877, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [19/50], Step [16/32], Loss: 0.4672, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [19/50], Step [17/32], Loss: 0.3919, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [19/50], Step [18/32], Loss: 0.3623, batch time: 0.68, accuracy:  83.00%\n",
      "Epoch [19/50], Step [19/32], Loss: 0.4116, batch time: 0.67, accuracy:  83.00%\n",
      "Epoch [19/50], Step [20/32], Loss: 0.3657, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [19/50], Step [21/32], Loss: 0.6154, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [19/50], Step [22/32], Loss: 0.3297, batch time: 0.72, accuracy:  89.00%\n",
      "Epoch [19/50], Step [23/32], Loss: 0.3773, batch time: 0.74, accuracy:  85.00%\n",
      "Epoch [19/50], Step [24/32], Loss: 0.3296, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [19/50], Step [25/32], Loss: 0.3598, batch time: 0.73, accuracy:  83.00%\n",
      "Epoch [19/50], Step [26/32], Loss: 0.4979, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [19/50], Step [27/32], Loss: 0.5323, batch time: 0.68, accuracy:  78.00%\n",
      "Epoch [19/50], Step [28/32], Loss: 0.4326, batch time: 0.59, accuracy:  80.00%\n",
      "Epoch [19/50], Step [29/32], Loss: 0.3442, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [19/50], Step [30/32], Loss: 0.3413, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [19/50], Step [31/32], Loss: 0.3218, batch time: 0.62, accuracy:  88.00%\n",
      "Epoch [19/50], Step [32/32], Loss: 0.4515, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [20/50], Step [1/32], Loss: 0.4315, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [20/50], Step [2/32], Loss: 0.3290, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [20/50], Step [3/32], Loss: 0.3928, batch time: 0.72, accuracy:  85.00%\n",
      "Epoch [20/50], Step [4/32], Loss: 0.4096, batch time: 0.90, accuracy:  83.00%\n",
      "Epoch [20/50], Step [5/32], Loss: 0.5330, batch time: 0.67, accuracy:  78.00%\n",
      "Epoch [20/50], Step [6/32], Loss: 0.4738, batch time: 0.70, accuracy:  78.00%\n",
      "Epoch [20/50], Step [7/32], Loss: 0.4099, batch time: 0.67, accuracy:  82.00%\n",
      "Epoch [20/50], Step [8/32], Loss: 0.5085, batch time: 0.66, accuracy:  73.00%\n",
      "Epoch [20/50], Step [9/32], Loss: 0.3880, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [20/50], Step [10/32], Loss: 0.4751, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [20/50], Step [11/32], Loss: 0.3488, batch time: 0.60, accuracy:  89.00%\n",
      "Epoch [20/50], Step [12/32], Loss: 0.4562, batch time: 0.63, accuracy:  80.00%\n",
      "Epoch [20/50], Step [13/32], Loss: 0.4330, batch time: 0.71, accuracy:  81.00%\n",
      "Epoch [20/50], Step [14/32], Loss: 0.4369, batch time: 0.59, accuracy:  77.00%\n",
      "Epoch [20/50], Step [15/32], Loss: 0.3384, batch time: 0.64, accuracy:  88.00%\n",
      "Epoch [20/50], Step [16/32], Loss: 0.4683, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [20/50], Step [17/32], Loss: 0.3275, batch time: 0.66, accuracy:  85.00%\n",
      "Epoch [20/50], Step [18/32], Loss: 0.3847, batch time: 0.73, accuracy:  83.00%\n",
      "Epoch [20/50], Step [19/32], Loss: 0.2974, batch time: 0.68, accuracy:  87.00%\n",
      "Epoch [20/50], Step [20/32], Loss: 0.4518, batch time: 0.64, accuracy:  77.00%\n",
      "Epoch [20/50], Step [21/32], Loss: 0.3339, batch time: 0.68, accuracy:  86.00%\n",
      "Epoch [20/50], Step [22/32], Loss: 0.3848, batch time: 0.65, accuracy:  87.00%\n",
      "Epoch [20/50], Step [23/32], Loss: 0.4072, batch time: 0.70, accuracy:  84.00%\n",
      "Epoch [20/50], Step [24/32], Loss: 0.4592, batch time: 0.62, accuracy:  78.00%\n",
      "Epoch [20/50], Step [25/32], Loss: 0.4392, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [20/50], Step [26/32], Loss: 0.3272, batch time: 0.65, accuracy:  88.00%\n",
      "Epoch [20/50], Step [27/32], Loss: 0.4984, batch time: 0.73, accuracy:  79.00%\n",
      "Epoch [20/50], Step [28/32], Loss: 0.3646, batch time: 0.90, accuracy:  85.00%\n",
      "Epoch [20/50], Step [29/32], Loss: 0.4408, batch time: 0.66, accuracy:  83.00%\n",
      "Epoch [20/50], Step [30/32], Loss: 0.4250, batch time: 0.73, accuracy:  83.00%\n",
      "Epoch [20/50], Step [31/32], Loss: 0.3674, batch time: 0.66, accuracy:  85.00%\n",
      "Epoch [20/50], Step [32/32], Loss: 0.4615, batch time: 0.59, accuracy:  82.00%\n",
      "Epoch [21/50], Step [1/32], Loss: 0.3555, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [21/50], Step [2/32], Loss: 0.4188, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [21/50], Step [3/32], Loss: 0.4664, batch time: 0.61, accuracy:  79.00%\n",
      "Epoch [21/50], Step [4/32], Loss: 0.4096, batch time: 0.73, accuracy:  82.00%\n",
      "Epoch [21/50], Step [5/32], Loss: 0.4055, batch time: 0.65, accuracy:  86.00%\n",
      "Epoch [21/50], Step [6/32], Loss: 0.3852, batch time: 0.70, accuracy:  85.00%\n",
      "Epoch [21/50], Step [7/32], Loss: 0.4253, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [21/50], Step [8/32], Loss: 0.4900, batch time: 0.68, accuracy:  83.00%\n",
      "Epoch [21/50], Step [9/32], Loss: 0.5404, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [21/50], Step [10/32], Loss: 0.3700, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [21/50], Step [11/32], Loss: 0.4094, batch time: 0.62, accuracy:  79.00%\n",
      "Epoch [21/50], Step [12/32], Loss: 0.3169, batch time: 0.67, accuracy:  89.00%\n",
      "Epoch [21/50], Step [13/32], Loss: 0.3894, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [21/50], Step [14/32], Loss: 0.2935, batch time: 0.71, accuracy:  91.00%\n",
      "Epoch [21/50], Step [15/32], Loss: 0.3428, batch time: 0.71, accuracy:  86.00%\n",
      "Epoch [21/50], Step [16/32], Loss: 0.3581, batch time: 0.69, accuracy:  87.00%\n",
      "Epoch [21/50], Step [17/32], Loss: 0.4670, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [21/50], Step [18/32], Loss: 0.4349, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [21/50], Step [19/32], Loss: 0.4103, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [21/50], Step [20/32], Loss: 0.4387, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [21/50], Step [21/32], Loss: 0.4790, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [21/50], Step [22/32], Loss: 0.2906, batch time: 0.69, accuracy:  88.00%\n",
      "Epoch [21/50], Step [23/32], Loss: 0.4442, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [21/50], Step [24/32], Loss: 0.4172, batch time: 0.65, accuracy:  86.00%\n",
      "Epoch [21/50], Step [25/32], Loss: 0.4118, batch time: 0.71, accuracy:  78.00%\n",
      "Epoch [21/50], Step [26/32], Loss: 0.3988, batch time: 0.82, accuracy:  86.00%\n",
      "Epoch [21/50], Step [27/32], Loss: 0.5118, batch time: 0.67, accuracy:  74.00%\n",
      "Epoch [21/50], Step [28/32], Loss: 0.3502, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [21/50], Step [29/32], Loss: 0.3986, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [21/50], Step [30/32], Loss: 0.4331, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [21/50], Step [31/32], Loss: 0.4871, batch time: 0.60, accuracy:  78.00%\n",
      "Epoch [21/50], Step [32/32], Loss: 0.3891, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [22/50], Step [1/32], Loss: 0.4381, batch time: 0.67, accuracy:  79.00%\n",
      "Epoch [22/50], Step [2/32], Loss: 0.4121, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [22/50], Step [3/32], Loss: 0.4335, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [22/50], Step [4/32], Loss: 0.4712, batch time: 0.65, accuracy:  79.00%\n",
      "Epoch [22/50], Step [5/32], Loss: 0.3808, batch time: 0.66, accuracy:  85.00%\n",
      "Epoch [22/50], Step [6/32], Loss: 0.3270, batch time: 0.62, accuracy:  91.00%\n",
      "Epoch [22/50], Step [7/32], Loss: 0.4515, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [22/50], Step [8/32], Loss: 0.3790, batch time: 0.64, accuracy:  85.00%\n",
      "Epoch [22/50], Step [9/32], Loss: 0.3796, batch time: 0.64, accuracy:  85.00%\n",
      "Epoch [22/50], Step [10/32], Loss: 0.3659, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [22/50], Step [11/32], Loss: 0.3723, batch time: 0.60, accuracy:  85.00%\n",
      "Epoch [22/50], Step [12/32], Loss: 0.4032, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [22/50], Step [13/32], Loss: 0.4041, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [22/50], Step [14/32], Loss: 0.3790, batch time: 0.61, accuracy:  86.00%\n",
      "Epoch [22/50], Step [15/32], Loss: 0.4110, batch time: 0.65, accuracy:  81.00%\n",
      "Epoch [22/50], Step [16/32], Loss: 0.4364, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [22/50], Step [17/32], Loss: 0.4326, batch time: 0.72, accuracy:  82.00%\n",
      "Epoch [22/50], Step [18/32], Loss: 0.4745, batch time: 0.77, accuracy:  82.00%\n",
      "Epoch [22/50], Step [19/32], Loss: 0.4106, batch time: 0.84, accuracy:  83.00%\n",
      "Epoch [22/50], Step [20/32], Loss: 0.5326, batch time: 0.69, accuracy:  74.00%\n",
      "Epoch [22/50], Step [21/32], Loss: 0.4031, batch time: 0.59, accuracy:  81.00%\n",
      "Epoch [22/50], Step [22/32], Loss: 0.4000, batch time: 0.70, accuracy:  85.00%\n",
      "Epoch [22/50], Step [23/32], Loss: 0.5185, batch time: 0.59, accuracy:  81.00%\n",
      "Epoch [22/50], Step [24/32], Loss: 0.3907, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [22/50], Step [25/32], Loss: 0.3317, batch time: 0.60, accuracy:  90.00%\n",
      "Epoch [22/50], Step [26/32], Loss: 0.3137, batch time: 0.68, accuracy:  89.00%\n",
      "Epoch [22/50], Step [27/32], Loss: 0.4906, batch time: 0.69, accuracy:  78.00%\n",
      "Epoch [22/50], Step [28/32], Loss: 0.3867, batch time: 0.68, accuracy:  82.00%\n",
      "Epoch [22/50], Step [29/32], Loss: 0.3247, batch time: 0.66, accuracy:  87.00%\n",
      "Epoch [22/50], Step [30/32], Loss: 0.3881, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [22/50], Step [31/32], Loss: 0.4894, batch time: 0.70, accuracy:  77.00%\n",
      "Epoch [22/50], Step [32/32], Loss: 0.3988, batch time: 0.67, accuracy:  85.00%\n",
      "Epoch [23/50], Step [1/32], Loss: 0.3610, batch time: 0.62, accuracy:  85.00%\n",
      "Epoch [23/50], Step [2/32], Loss: 0.3549, batch time: 0.59, accuracy:  85.00%\n",
      "Epoch [23/50], Step [3/32], Loss: 0.4168, batch time: 0.60, accuracy:  85.00%\n",
      "Epoch [23/50], Step [4/32], Loss: 0.3115, batch time: 0.59, accuracy:  88.00%\n",
      "Epoch [23/50], Step [5/32], Loss: 0.4794, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [23/50], Step [6/32], Loss: 0.5172, batch time: 0.73, accuracy:  79.00%\n",
      "Epoch [23/50], Step [7/32], Loss: 0.5359, batch time: 0.55, accuracy:  77.00%\n",
      "Epoch [23/50], Step [8/32], Loss: 0.4866, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [23/50], Step [9/32], Loss: 0.2924, batch time: 0.52, accuracy:  92.00%\n",
      "Epoch [23/50], Step [10/32], Loss: 0.3618, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [23/50], Step [11/32], Loss: 0.4035, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [23/50], Step [12/32], Loss: 0.3751, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [23/50], Step [13/32], Loss: 0.4673, batch time: 0.58, accuracy:  80.00%\n",
      "Epoch [23/50], Step [14/32], Loss: 0.4586, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [23/50], Step [15/32], Loss: 0.4480, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [23/50], Step [16/32], Loss: 0.4426, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [23/50], Step [17/32], Loss: 0.3648, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [23/50], Step [18/32], Loss: 0.3718, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [23/50], Step [19/32], Loss: 0.3842, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [23/50], Step [20/32], Loss: 0.3694, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [23/50], Step [21/32], Loss: 0.3599, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [23/50], Step [22/32], Loss: 0.4447, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [23/50], Step [23/32], Loss: 0.3575, batch time: 0.51, accuracy:  86.00%\n",
      "Epoch [23/50], Step [24/32], Loss: 0.4267, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [23/50], Step [25/32], Loss: 0.3593, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [23/50], Step [26/32], Loss: 0.3971, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [23/50], Step [27/32], Loss: 0.3923, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [23/50], Step [28/32], Loss: 0.4762, batch time: 0.51, accuracy:  73.00%\n",
      "Epoch [23/50], Step [29/32], Loss: 0.4611, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [23/50], Step [30/32], Loss: 0.3623, batch time: 0.52, accuracy:  87.00%\n",
      "Epoch [23/50], Step [31/32], Loss: 0.5630, batch time: 0.52, accuracy:  75.00%\n",
      "Epoch [23/50], Step [32/32], Loss: 0.4183, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [24/50], Step [1/32], Loss: 0.4198, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [24/50], Step [2/32], Loss: 0.3957, batch time: 0.56, accuracy:  86.00%\n",
      "Epoch [24/50], Step [3/32], Loss: 0.3340, batch time: 0.54, accuracy:  89.00%\n",
      "Epoch [24/50], Step [4/32], Loss: 0.3477, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [24/50], Step [5/32], Loss: 0.4868, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [24/50], Step [6/32], Loss: 0.4169, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [24/50], Step [7/32], Loss: 0.4259, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [24/50], Step [8/32], Loss: 0.5437, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [24/50], Step [9/32], Loss: 0.3703, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [24/50], Step [10/32], Loss: 0.4999, batch time: 0.56, accuracy:  75.00%\n",
      "Epoch [24/50], Step [11/32], Loss: 0.3815, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [24/50], Step [12/32], Loss: 0.4369, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [24/50], Step [13/32], Loss: 0.4458, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [24/50], Step [14/32], Loss: 0.3884, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [24/50], Step [15/32], Loss: 0.4062, batch time: 0.51, accuracy:  80.00%\n",
      "Epoch [24/50], Step [16/32], Loss: 0.3587, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [24/50], Step [17/32], Loss: 0.2710, batch time: 0.54, accuracy:  90.00%\n",
      "Epoch [24/50], Step [18/32], Loss: 0.4791, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [24/50], Step [19/32], Loss: 0.4385, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [24/50], Step [20/32], Loss: 0.3121, batch time: 0.51, accuracy:  87.00%\n",
      "Epoch [24/50], Step [21/32], Loss: 0.4398, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [24/50], Step [22/32], Loss: 0.3447, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [24/50], Step [23/32], Loss: 0.4209, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [24/50], Step [24/32], Loss: 0.4395, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [24/50], Step [25/32], Loss: 0.3334, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [24/50], Step [26/32], Loss: 0.4372, batch time: 0.51, accuracy:  81.00%\n",
      "Epoch [24/50], Step [27/32], Loss: 0.4119, batch time: 0.59, accuracy:  80.00%\n",
      "Epoch [24/50], Step [28/32], Loss: 0.4139, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [24/50], Step [29/32], Loss: 0.4517, batch time: 0.53, accuracy:  78.00%\n",
      "Epoch [24/50], Step [30/32], Loss: 0.4780, batch time: 0.56, accuracy:  76.00%\n",
      "Epoch [24/50], Step [31/32], Loss: 0.4485, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [24/50], Step [32/32], Loss: 0.4187, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [25/50], Step [1/32], Loss: 0.4184, batch time: 0.57, accuracy:  85.00%\n",
      "Epoch [25/50], Step [2/32], Loss: 0.4959, batch time: 0.53, accuracy:  76.00%\n",
      "Epoch [25/50], Step [3/32], Loss: 0.4708, batch time: 0.53, accuracy:  78.00%\n",
      "Epoch [25/50], Step [4/32], Loss: 0.3720, batch time: 0.51, accuracy:  90.00%\n",
      "Epoch [25/50], Step [5/32], Loss: 0.3753, batch time: 0.51, accuracy:  85.00%\n",
      "Epoch [25/50], Step [6/32], Loss: 0.4362, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [25/50], Step [7/32], Loss: 0.3590, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [25/50], Step [8/32], Loss: 0.3953, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [25/50], Step [9/32], Loss: 0.3593, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [25/50], Step [10/32], Loss: 0.3914, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [25/50], Step [11/32], Loss: 0.3468, batch time: 0.57, accuracy:  85.00%\n",
      "Epoch [25/50], Step [12/32], Loss: 0.3605, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [25/50], Step [13/32], Loss: 0.4461, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [25/50], Step [14/32], Loss: 0.2931, batch time: 0.56, accuracy:  89.00%\n",
      "Epoch [25/50], Step [15/32], Loss: 0.5998, batch time: 0.56, accuracy:  74.00%\n",
      "Epoch [25/50], Step [16/32], Loss: 0.3749, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [25/50], Step [17/32], Loss: 0.3603, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [25/50], Step [18/32], Loss: 0.4269, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [25/50], Step [19/32], Loss: 0.3694, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [25/50], Step [20/32], Loss: 0.4346, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [25/50], Step [21/32], Loss: 0.4083, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [25/50], Step [22/32], Loss: 0.3963, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [25/50], Step [23/32], Loss: 0.3550, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [25/50], Step [24/32], Loss: 0.4535, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [25/50], Step [25/32], Loss: 0.4421, batch time: 0.56, accuracy:  76.00%\n",
      "Epoch [25/50], Step [26/32], Loss: 0.3678, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [25/50], Step [27/32], Loss: 0.4647, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [25/50], Step [28/32], Loss: 0.3952, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [25/50], Step [29/32], Loss: 0.4030, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [25/50], Step [30/32], Loss: 0.4002, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [25/50], Step [31/32], Loss: 0.4245, batch time: 0.57, accuracy:  82.00%\n",
      "Epoch [25/50], Step [32/32], Loss: 0.4367, batch time: 0.54, accuracy:  78.00%\n",
      "Epoch [26/50], Step [1/32], Loss: 0.3764, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [26/50], Step [2/32], Loss: 0.3466, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [26/50], Step [3/32], Loss: 0.4129, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [26/50], Step [4/32], Loss: 0.3820, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [26/50], Step [5/32], Loss: 0.4686, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [26/50], Step [6/32], Loss: 0.3902, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [26/50], Step [7/32], Loss: 0.2999, batch time: 0.62, accuracy:  92.00%\n",
      "Epoch [26/50], Step [8/32], Loss: 0.4150, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [26/50], Step [9/32], Loss: 0.3901, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [26/50], Step [10/32], Loss: 0.3964, batch time: 0.55, accuracy:  77.00%\n",
      "Epoch [26/50], Step [11/32], Loss: 0.4563, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [26/50], Step [12/32], Loss: 0.4362, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [26/50], Step [13/32], Loss: 0.4307, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [26/50], Step [14/32], Loss: 0.4031, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [26/50], Step [15/32], Loss: 0.4396, batch time: 0.57, accuracy:  81.00%\n",
      "Epoch [26/50], Step [16/32], Loss: 0.3960, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [26/50], Step [17/32], Loss: 0.3589, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [26/50], Step [18/32], Loss: 0.4731, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [26/50], Step [19/32], Loss: 0.3681, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [26/50], Step [20/32], Loss: 0.5089, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [26/50], Step [21/32], Loss: 0.4047, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [26/50], Step [22/32], Loss: 0.3844, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [26/50], Step [23/32], Loss: 0.3689, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [26/50], Step [24/32], Loss: 0.4444, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [26/50], Step [25/32], Loss: 0.4539, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [26/50], Step [26/32], Loss: 0.3876, batch time: 0.57, accuracy:  85.00%\n",
      "Epoch [26/50], Step [27/32], Loss: 0.3742, batch time: 0.56, accuracy:  86.00%\n",
      "Epoch [26/50], Step [28/32], Loss: 0.3750, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [26/50], Step [29/32], Loss: 0.3980, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [26/50], Step [30/32], Loss: 0.3830, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [26/50], Step [31/32], Loss: 0.5076, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [26/50], Step [32/32], Loss: 0.4013, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [27/50], Step [1/32], Loss: 0.4490, batch time: 0.56, accuracy:  76.00%\n",
      "Epoch [27/50], Step [2/32], Loss: 0.3593, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [27/50], Step [3/32], Loss: 0.5057, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [27/50], Step [4/32], Loss: 0.4212, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [27/50], Step [5/32], Loss: 0.4575, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [27/50], Step [6/32], Loss: 0.4342, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [27/50], Step [7/32], Loss: 0.4677, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [27/50], Step [8/32], Loss: 0.3733, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [27/50], Step [9/32], Loss: 0.4426, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [27/50], Step [10/32], Loss: 0.3714, batch time: 0.55, accuracy:  90.00%\n",
      "Epoch [27/50], Step [11/32], Loss: 0.4780, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [27/50], Step [12/32], Loss: 0.3602, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [27/50], Step [13/32], Loss: 0.3390, batch time: 0.53, accuracy:  87.00%\n",
      "Epoch [27/50], Step [14/32], Loss: 0.3866, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [27/50], Step [15/32], Loss: 0.4057, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [27/50], Step [16/32], Loss: 0.3899, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [27/50], Step [17/32], Loss: 0.4264, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [27/50], Step [18/32], Loss: 0.3633, batch time: 0.51, accuracy:  82.00%\n",
      "Epoch [27/50], Step [19/32], Loss: 0.4390, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [27/50], Step [20/32], Loss: 0.3248, batch time: 0.51, accuracy:  88.00%\n",
      "Epoch [27/50], Step [21/32], Loss: 0.4164, batch time: 0.52, accuracy:  76.00%\n",
      "Epoch [27/50], Step [22/32], Loss: 0.4506, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [27/50], Step [23/32], Loss: 0.4046, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [27/50], Step [24/32], Loss: 0.3768, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [27/50], Step [25/32], Loss: 0.3705, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [27/50], Step [26/32], Loss: 0.4088, batch time: 0.51, accuracy:  84.00%\n",
      "Epoch [27/50], Step [27/32], Loss: 0.3891, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [27/50], Step [28/32], Loss: 0.4830, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [27/50], Step [29/32], Loss: 0.2183, batch time: 0.63, accuracy:  92.00%\n",
      "Epoch [27/50], Step [30/32], Loss: 0.4671, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [27/50], Step [31/32], Loss: 0.5248, batch time: 0.55, accuracy:  76.00%\n",
      "Epoch [27/50], Step [32/32], Loss: 0.3835, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [28/50], Step [1/32], Loss: 0.3503, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [28/50], Step [2/32], Loss: 0.4398, batch time: 0.52, accuracy:  76.00%\n",
      "Epoch [28/50], Step [3/32], Loss: 0.4031, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [28/50], Step [4/32], Loss: 0.3535, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [28/50], Step [5/32], Loss: 0.5405, batch time: 0.52, accuracy:  77.00%\n",
      "Epoch [28/50], Step [6/32], Loss: 0.4079, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [28/50], Step [7/32], Loss: 0.3597, batch time: 0.52, accuracy:  86.00%\n",
      "Epoch [28/50], Step [8/32], Loss: 0.5437, batch time: 0.54, accuracy:  71.00%\n",
      "Epoch [28/50], Step [9/32], Loss: 0.3990, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [28/50], Step [10/32], Loss: 0.4415, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [28/50], Step [11/32], Loss: 0.4191, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [28/50], Step [12/32], Loss: 0.3888, batch time: 0.51, accuracy:  83.00%\n",
      "Epoch [28/50], Step [13/32], Loss: 0.4083, batch time: 0.51, accuracy:  86.00%\n",
      "Epoch [28/50], Step [14/32], Loss: 0.3367, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [28/50], Step [15/32], Loss: 0.5059, batch time: 0.57, accuracy:  79.00%\n",
      "Epoch [28/50], Step [16/32], Loss: 0.2726, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [28/50], Step [17/32], Loss: 0.4565, batch time: 0.57, accuracy:  79.00%\n",
      "Epoch [28/50], Step [18/32], Loss: 0.4155, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [28/50], Step [19/32], Loss: 0.3960, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [28/50], Step [20/32], Loss: 0.3933, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [28/50], Step [21/32], Loss: 0.3783, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [28/50], Step [22/32], Loss: 0.4164, batch time: 0.51, accuracy:  86.00%\n",
      "Epoch [28/50], Step [23/32], Loss: 0.4210, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [28/50], Step [24/32], Loss: 0.3579, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [28/50], Step [25/32], Loss: 0.3576, batch time: 0.51, accuracy:  85.00%\n",
      "Epoch [28/50], Step [26/32], Loss: 0.3667, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [28/50], Step [27/32], Loss: 0.3590, batch time: 0.63, accuracy:  91.00%\n",
      "Epoch [28/50], Step [28/32], Loss: 0.4162, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [28/50], Step [29/32], Loss: 0.4107, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [28/50], Step [30/32], Loss: 0.4936, batch time: 0.55, accuracy:  72.00%\n",
      "Epoch [28/50], Step [31/32], Loss: 0.3967, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [28/50], Step [32/32], Loss: 0.4183, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [29/50], Step [1/32], Loss: 0.4488, batch time: 0.52, accuracy:  74.00%\n",
      "Epoch [29/50], Step [2/32], Loss: 0.4137, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [29/50], Step [3/32], Loss: 0.4610, batch time: 0.53, accuracy:  75.00%\n",
      "Epoch [29/50], Step [4/32], Loss: 0.3616, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [29/50], Step [5/32], Loss: 0.3376, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [29/50], Step [6/32], Loss: 0.4328, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [29/50], Step [7/32], Loss: 0.3805, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [29/50], Step [8/32], Loss: 0.3420, batch time: 0.53, accuracy:  87.00%\n",
      "Epoch [29/50], Step [9/32], Loss: 0.3649, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [29/50], Step [10/32], Loss: 0.4043, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [29/50], Step [11/32], Loss: 0.4906, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [29/50], Step [12/32], Loss: 0.3526, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [29/50], Step [13/32], Loss: 0.3906, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [29/50], Step [14/32], Loss: 0.3252, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [29/50], Step [15/32], Loss: 0.4599, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [29/50], Step [16/32], Loss: 0.3829, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [29/50], Step [17/32], Loss: 0.3338, batch time: 0.52, accuracy:  88.00%\n",
      "Epoch [29/50], Step [18/32], Loss: 0.3980, batch time: 0.53, accuracy:  79.00%\n",
      "Epoch [29/50], Step [19/32], Loss: 0.4184, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [29/50], Step [20/32], Loss: 0.3832, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [29/50], Step [21/32], Loss: 0.4863, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [29/50], Step [22/32], Loss: 0.3950, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [29/50], Step [23/32], Loss: 0.4763, batch time: 0.57, accuracy:  82.00%\n",
      "Epoch [29/50], Step [24/32], Loss: 0.3851, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [29/50], Step [25/32], Loss: 0.3739, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [29/50], Step [26/32], Loss: 0.3797, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [29/50], Step [27/32], Loss: 0.4406, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [29/50], Step [28/32], Loss: 0.3593, batch time: 0.57, accuracy:  86.00%\n",
      "Epoch [29/50], Step [29/32], Loss: 0.4661, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [29/50], Step [30/32], Loss: 0.4392, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [29/50], Step [31/32], Loss: 0.4628, batch time: 0.55, accuracy:  77.00%\n",
      "Epoch [29/50], Step [32/32], Loss: 0.4385, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [30/50], Step [1/32], Loss: 0.3407, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [30/50], Step [2/32], Loss: 0.3669, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [30/50], Step [3/32], Loss: 0.3654, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [30/50], Step [4/32], Loss: 0.4089, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [30/50], Step [5/32], Loss: 0.3658, batch time: 0.51, accuracy:  81.00%\n",
      "Epoch [30/50], Step [6/32], Loss: 0.4587, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [30/50], Step [7/32], Loss: 0.3995, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [30/50], Step [8/32], Loss: 0.3199, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [30/50], Step [9/32], Loss: 0.4391, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [30/50], Step [10/32], Loss: 0.4221, batch time: 0.57, accuracy:  83.00%\n",
      "Epoch [30/50], Step [11/32], Loss: 0.4316, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [30/50], Step [12/32], Loss: 0.4294, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [30/50], Step [13/32], Loss: 0.3981, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [30/50], Step [14/32], Loss: 0.3907, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [30/50], Step [15/32], Loss: 0.4962, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [30/50], Step [16/32], Loss: 0.4828, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [30/50], Step [17/32], Loss: 0.3486, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [30/50], Step [18/32], Loss: 0.4413, batch time: 0.51, accuracy:  82.00%\n",
      "Epoch [30/50], Step [19/32], Loss: 0.4580, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [30/50], Step [20/32], Loss: 0.3761, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [30/50], Step [21/32], Loss: 0.3905, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [30/50], Step [22/32], Loss: 0.4519, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [30/50], Step [23/32], Loss: 0.4696, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [30/50], Step [24/32], Loss: 0.2823, batch time: 0.56, accuracy:  91.00%\n",
      "Epoch [30/50], Step [25/32], Loss: 0.3702, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [30/50], Step [26/32], Loss: 0.4200, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [30/50], Step [27/32], Loss: 0.4840, batch time: 0.53, accuracy:  76.00%\n",
      "Epoch [30/50], Step [28/32], Loss: 0.3553, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [30/50], Step [29/32], Loss: 0.4942, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [30/50], Step [30/32], Loss: 0.4282, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [30/50], Step [31/32], Loss: 0.4165, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [30/50], Step [32/32], Loss: 0.4253, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [31/50], Step [1/32], Loss: 0.4054, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [31/50], Step [2/32], Loss: 0.4253, batch time: 0.57, accuracy:  80.00%\n",
      "Epoch [31/50], Step [3/32], Loss: 0.4242, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [31/50], Step [4/32], Loss: 0.3594, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [31/50], Step [5/32], Loss: 0.3350, batch time: 0.55, accuracy:  91.00%\n",
      "Epoch [31/50], Step [6/32], Loss: 0.4221, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [31/50], Step [7/32], Loss: 0.3483, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [31/50], Step [8/32], Loss: 0.3967, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [31/50], Step [9/32], Loss: 0.3804, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [31/50], Step [10/32], Loss: 0.4554, batch time: 0.62, accuracy:  80.00%\n",
      "Epoch [31/50], Step [11/32], Loss: 0.4570, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [31/50], Step [12/32], Loss: 0.4082, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [31/50], Step [13/32], Loss: 0.4010, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [31/50], Step [14/32], Loss: 0.4643, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [31/50], Step [15/32], Loss: 0.4073, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [31/50], Step [16/32], Loss: 0.4530, batch time: 0.51, accuracy:  81.00%\n",
      "Epoch [31/50], Step [17/32], Loss: 0.3913, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [31/50], Step [18/32], Loss: 0.4751, batch time: 0.52, accuracy:  74.00%\n",
      "Epoch [31/50], Step [19/32], Loss: 0.4371, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [31/50], Step [20/32], Loss: 0.3453, batch time: 0.58, accuracy:  82.00%\n",
      "Epoch [31/50], Step [21/32], Loss: 0.4289, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [31/50], Step [22/32], Loss: 0.3653, batch time: 0.51, accuracy:  84.00%\n",
      "Epoch [31/50], Step [23/32], Loss: 0.4168, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [31/50], Step [24/32], Loss: 0.4390, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [31/50], Step [25/32], Loss: 0.3910, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [31/50], Step [26/32], Loss: 0.4325, batch time: 0.51, accuracy:  82.00%\n",
      "Epoch [31/50], Step [27/32], Loss: 0.4587, batch time: 0.54, accuracy:  78.00%\n",
      "Epoch [31/50], Step [28/32], Loss: 0.4663, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [31/50], Step [29/32], Loss: 0.3949, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [31/50], Step [30/32], Loss: 0.3733, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [31/50], Step [31/32], Loss: 0.3859, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [31/50], Step [32/32], Loss: 0.2818, batch time: 0.55, accuracy:  91.00%\n",
      "Epoch [32/50], Step [1/32], Loss: 0.4570, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [32/50], Step [2/32], Loss: 0.4794, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [32/50], Step [3/32], Loss: 0.3631, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [32/50], Step [4/32], Loss: 0.4079, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [32/50], Step [5/32], Loss: 0.4487, batch time: 0.51, accuracy:  79.00%\n",
      "Epoch [32/50], Step [6/32], Loss: 0.3714, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [32/50], Step [7/32], Loss: 0.4442, batch time: 0.52, accuracy:  79.00%\n",
      "Epoch [32/50], Step [8/32], Loss: 0.3585, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [32/50], Step [9/32], Loss: 0.4753, batch time: 0.51, accuracy:  78.00%\n",
      "Epoch [32/50], Step [10/32], Loss: 0.3479, batch time: 0.53, accuracy:  89.00%\n",
      "Epoch [32/50], Step [11/32], Loss: 0.3808, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [32/50], Step [12/32], Loss: 0.5325, batch time: 0.52, accuracy:  75.00%\n",
      "Epoch [32/50], Step [13/32], Loss: 0.4136, batch time: 0.52, accuracy:  79.00%\n",
      "Epoch [32/50], Step [14/32], Loss: 0.3850, batch time: 0.51, accuracy:  85.00%\n",
      "Epoch [32/50], Step [15/32], Loss: 0.3245, batch time: 0.52, accuracy:  90.00%\n",
      "Epoch [32/50], Step [16/32], Loss: 0.5305, batch time: 0.54, accuracy:  75.00%\n",
      "Epoch [32/50], Step [17/32], Loss: 0.4580, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [32/50], Step [18/32], Loss: 0.3476, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [32/50], Step [19/32], Loss: 0.3488, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [32/50], Step [20/32], Loss: 0.3958, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [32/50], Step [21/32], Loss: 0.3549, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [32/50], Step [22/32], Loss: 0.3966, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [32/50], Step [23/32], Loss: 0.4691, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [32/50], Step [24/32], Loss: 0.3527, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [32/50], Step [25/32], Loss: 0.4411, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [32/50], Step [26/32], Loss: 0.4128, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [32/50], Step [27/32], Loss: 0.4401, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [32/50], Step [28/32], Loss: 0.3884, batch time: 0.57, accuracy:  83.00%\n",
      "Epoch [32/50], Step [29/32], Loss: 0.3944, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [32/50], Step [30/32], Loss: 0.4067, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [32/50], Step [31/32], Loss: 0.3947, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [32/50], Step [32/32], Loss: 0.3963, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [33/50], Step [1/32], Loss: 0.4215, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [33/50], Step [2/32], Loss: 0.4563, batch time: 0.51, accuracy:  84.00%\n",
      "Epoch [33/50], Step [3/32], Loss: 0.4501, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [33/50], Step [4/32], Loss: 0.3734, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [33/50], Step [5/32], Loss: 0.2966, batch time: 0.54, accuracy:  91.00%\n",
      "Epoch [33/50], Step [6/32], Loss: 0.3734, batch time: 0.57, accuracy:  83.00%\n",
      "Epoch [33/50], Step [7/32], Loss: 0.4040, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [33/50], Step [8/32], Loss: 0.3336, batch time: 0.55, accuracy:  89.00%\n",
      "Epoch [33/50], Step [9/32], Loss: 0.5562, batch time: 0.51, accuracy:  74.00%\n",
      "Epoch [33/50], Step [10/32], Loss: 0.3626, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [33/50], Step [11/32], Loss: 0.3257, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [33/50], Step [12/32], Loss: 0.4702, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [33/50], Step [13/32], Loss: 0.4495, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [33/50], Step [14/32], Loss: 0.4650, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [33/50], Step [15/32], Loss: 0.3708, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [33/50], Step [16/32], Loss: 0.4449, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [33/50], Step [17/32], Loss: 0.4351, batch time: 0.57, accuracy:  80.00%\n",
      "Epoch [33/50], Step [18/32], Loss: 0.3938, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [33/50], Step [19/32], Loss: 0.3585, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [33/50], Step [20/32], Loss: 0.4121, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [33/50], Step [21/32], Loss: 0.5035, batch time: 0.52, accuracy:  79.00%\n",
      "Epoch [33/50], Step [22/32], Loss: 0.3965, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [33/50], Step [23/32], Loss: 0.3743, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [33/50], Step [24/32], Loss: 0.3334, batch time: 0.53, accuracy:  87.00%\n",
      "Epoch [33/50], Step [25/32], Loss: 0.5168, batch time: 0.53, accuracy:  79.00%\n",
      "Epoch [33/50], Step [26/32], Loss: 0.3109, batch time: 0.57, accuracy:  87.00%\n",
      "Epoch [33/50], Step [27/32], Loss: 0.2908, batch time: 0.53, accuracy:  89.00%\n",
      "Epoch [33/50], Step [28/32], Loss: 0.3602, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [33/50], Step [29/32], Loss: 0.4258, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [33/50], Step [30/32], Loss: 0.4572, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [33/50], Step [31/32], Loss: 0.4096, batch time: 0.51, accuracy:  82.00%\n",
      "Epoch [33/50], Step [32/32], Loss: 0.4816, batch time: 0.52, accuracy:  76.00%\n",
      "Epoch [34/50], Step [1/32], Loss: 0.4773, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [34/50], Step [2/32], Loss: 0.3858, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [34/50], Step [3/32], Loss: 0.4164, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [34/50], Step [4/32], Loss: 0.3424, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [34/50], Step [5/32], Loss: 0.4711, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [34/50], Step [6/32], Loss: 0.3654, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [34/50], Step [7/32], Loss: 0.3216, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [34/50], Step [8/32], Loss: 0.4015, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [34/50], Step [9/32], Loss: 0.3738, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [34/50], Step [10/32], Loss: 0.4382, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [34/50], Step [11/32], Loss: 0.4691, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [34/50], Step [12/32], Loss: 0.4845, batch time: 0.55, accuracy:  75.00%\n",
      "Epoch [34/50], Step [13/32], Loss: 0.4003, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [34/50], Step [14/32], Loss: 0.4461, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [34/50], Step [15/32], Loss: 0.4266, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [34/50], Step [16/32], Loss: 0.4564, batch time: 0.57, accuracy:  77.00%\n",
      "Epoch [34/50], Step [17/32], Loss: 0.4359, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [34/50], Step [18/32], Loss: 0.3764, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [34/50], Step [19/32], Loss: 0.3894, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [34/50], Step [20/32], Loss: 0.3395, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [34/50], Step [21/32], Loss: 0.4847, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [34/50], Step [22/32], Loss: 0.4739, batch time: 0.53, accuracy:  79.00%\n",
      "Epoch [34/50], Step [23/32], Loss: 0.4020, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [34/50], Step [24/32], Loss: 0.4553, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [34/50], Step [25/32], Loss: 0.3659, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [34/50], Step [26/32], Loss: 0.3237, batch time: 0.51, accuracy:  87.00%\n",
      "Epoch [34/50], Step [27/32], Loss: 0.3581, batch time: 0.52, accuracy:  86.00%\n",
      "Epoch [34/50], Step [28/32], Loss: 0.4446, batch time: 0.52, accuracy:  80.00%\n",
      "Epoch [34/50], Step [29/32], Loss: 0.4375, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [34/50], Step [30/32], Loss: 0.4658, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [34/50], Step [31/32], Loss: 0.3482, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [34/50], Step [32/32], Loss: 0.3829, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [35/50], Step [1/32], Loss: 0.3880, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [35/50], Step [2/32], Loss: 0.4413, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [35/50], Step [3/32], Loss: 0.3890, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [35/50], Step [4/32], Loss: 0.3992, batch time: 0.57, accuracy:  80.00%\n",
      "Epoch [35/50], Step [5/32], Loss: 0.3939, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [35/50], Step [6/32], Loss: 0.4286, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [35/50], Step [7/32], Loss: 0.3835, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [35/50], Step [8/32], Loss: 0.3391, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [35/50], Step [9/32], Loss: 0.3581, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [35/50], Step [10/32], Loss: 0.3612, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [35/50], Step [11/32], Loss: 0.3493, batch time: 0.56, accuracy:  89.00%\n",
      "Epoch [35/50], Step [12/32], Loss: 0.4478, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [35/50], Step [13/32], Loss: 0.4526, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [35/50], Step [14/32], Loss: 0.4459, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [35/50], Step [15/32], Loss: 0.3712, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [35/50], Step [16/32], Loss: 0.3954, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [35/50], Step [17/32], Loss: 0.4188, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [35/50], Step [18/32], Loss: 0.3690, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [35/50], Step [19/32], Loss: 0.3712, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [35/50], Step [20/32], Loss: 0.4718, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [35/50], Step [21/32], Loss: 0.4651, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [35/50], Step [22/32], Loss: 0.4629, batch time: 0.52, accuracy:  79.00%\n",
      "Epoch [35/50], Step [23/32], Loss: 0.4509, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [35/50], Step [24/32], Loss: 0.4289, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [35/50], Step [25/32], Loss: 0.4500, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [35/50], Step [26/32], Loss: 0.3868, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [35/50], Step [27/32], Loss: 0.3987, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [35/50], Step [28/32], Loss: 0.3625, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [35/50], Step [29/32], Loss: 0.4955, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [35/50], Step [30/32], Loss: 0.5313, batch time: 0.56, accuracy:  75.00%\n",
      "Epoch [35/50], Step [31/32], Loss: 0.4558, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [35/50], Step [32/32], Loss: 0.3230, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch 00085: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch [36/50], Step [1/32], Loss: 0.4772, batch time: 0.58, accuracy:  79.00%\n",
      "Epoch [36/50], Step [2/32], Loss: 0.3928, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [36/50], Step [3/32], Loss: 0.3167, batch time: 0.56, accuracy:  91.00%\n",
      "Epoch [36/50], Step [4/32], Loss: 0.3551, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [36/50], Step [5/32], Loss: 0.5061, batch time: 0.54, accuracy:  76.00%\n",
      "Epoch [36/50], Step [6/32], Loss: 0.3996, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [36/50], Step [7/32], Loss: 0.3387, batch time: 0.57, accuracy:  86.00%\n",
      "Epoch [36/50], Step [8/32], Loss: 0.3948, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [36/50], Step [9/32], Loss: 0.4371, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [36/50], Step [10/32], Loss: 0.3511, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [36/50], Step [11/32], Loss: 0.2802, batch time: 0.55, accuracy:  92.00%\n",
      "Epoch [36/50], Step [12/32], Loss: 0.4828, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [36/50], Step [13/32], Loss: 0.3644, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [36/50], Step [14/32], Loss: 0.4855, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [36/50], Step [15/32], Loss: 0.4340, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [36/50], Step [16/32], Loss: 0.4703, batch time: 0.57, accuracy:  82.00%\n",
      "Epoch [36/50], Step [17/32], Loss: 0.3969, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [36/50], Step [18/32], Loss: 0.4619, batch time: 0.53, accuracy:  73.00%\n",
      "Epoch [36/50], Step [19/32], Loss: 0.4167, batch time: 0.52, accuracy:  80.00%\n",
      "Epoch [36/50], Step [20/32], Loss: 0.4649, batch time: 0.52, accuracy:  77.00%\n",
      "Epoch [36/50], Step [21/32], Loss: 0.3938, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [36/50], Step [22/32], Loss: 0.4348, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [36/50], Step [23/32], Loss: 0.4279, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [36/50], Step [24/32], Loss: 0.3621, batch time: 0.57, accuracy:  86.00%\n",
      "Epoch [36/50], Step [25/32], Loss: 0.3424, batch time: 0.57, accuracy:  86.00%\n",
      "Epoch [36/50], Step [26/32], Loss: 0.4091, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [36/50], Step [27/32], Loss: 0.3404, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [36/50], Step [28/32], Loss: 0.4668, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [36/50], Step [29/32], Loss: 0.4025, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [36/50], Step [30/32], Loss: 0.4221, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [36/50], Step [31/32], Loss: 0.4279, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [36/50], Step [32/32], Loss: 0.3460, batch time: 0.53, accuracy:  87.00%\n",
      "Epoch [37/50], Step [1/32], Loss: 0.3974, batch time: 0.51, accuracy:  81.00%\n",
      "Epoch [37/50], Step [2/32], Loss: 0.4755, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [37/50], Step [3/32], Loss: 0.4789, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [37/50], Step [4/32], Loss: 0.4298, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [37/50], Step [5/32], Loss: 0.3317, batch time: 0.56, accuracy:  91.00%\n",
      "Epoch [37/50], Step [6/32], Loss: 0.4118, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [37/50], Step [7/32], Loss: 0.4431, batch time: 0.56, accuracy:  76.00%\n",
      "Epoch [37/50], Step [8/32], Loss: 0.3474, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [37/50], Step [9/32], Loss: 0.3535, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [37/50], Step [10/32], Loss: 0.4181, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [37/50], Step [11/32], Loss: 0.3244, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [37/50], Step [12/32], Loss: 0.3780, batch time: 0.52, accuracy:  86.00%\n",
      "Epoch [37/50], Step [13/32], Loss: 0.3965, batch time: 0.51, accuracy:  83.00%\n",
      "Epoch [37/50], Step [14/32], Loss: 0.3591, batch time: 0.53, accuracy:  92.00%\n",
      "Epoch [37/50], Step [15/32], Loss: 0.4015, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [37/50], Step [16/32], Loss: 0.3613, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [37/50], Step [17/32], Loss: 0.4620, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [37/50], Step [18/32], Loss: 0.3681, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [37/50], Step [19/32], Loss: 0.3985, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [37/50], Step [20/32], Loss: 0.4914, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [37/50], Step [21/32], Loss: 0.4720, batch time: 0.53, accuracy:  80.00%\n",
      "Epoch [37/50], Step [22/32], Loss: 0.3711, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [37/50], Step [23/32], Loss: 0.4653, batch time: 0.57, accuracy:  77.00%\n",
      "Epoch [37/50], Step [24/32], Loss: 0.3193, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [37/50], Step [25/32], Loss: 0.5441, batch time: 0.52, accuracy:  77.00%\n",
      "Epoch [37/50], Step [26/32], Loss: 0.3763, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [37/50], Step [27/32], Loss: 0.4634, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [37/50], Step [28/32], Loss: 0.4751, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [37/50], Step [29/32], Loss: 0.3871, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [37/50], Step [30/32], Loss: 0.3408, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [37/50], Step [31/32], Loss: 0.3731, batch time: 0.52, accuracy:  86.00%\n",
      "Epoch [37/50], Step [32/32], Loss: 0.3750, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [38/50], Step [1/32], Loss: 0.3650, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [38/50], Step [2/32], Loss: 0.3963, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [38/50], Step [3/32], Loss: 0.4898, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [38/50], Step [4/32], Loss: 0.3477, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [38/50], Step [5/32], Loss: 0.2941, batch time: 0.62, accuracy:  89.00%\n",
      "Epoch [38/50], Step [6/32], Loss: 0.4346, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [38/50], Step [7/32], Loss: 0.4937, batch time: 0.57, accuracy:  79.00%\n",
      "Epoch [38/50], Step [8/32], Loss: 0.3579, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [38/50], Step [9/32], Loss: 0.3381, batch time: 0.58, accuracy:  88.00%\n",
      "Epoch [38/50], Step [10/32], Loss: 0.4318, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [38/50], Step [11/32], Loss: 0.4480, batch time: 0.51, accuracy:  80.00%\n",
      "Epoch [38/50], Step [12/32], Loss: 0.3461, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [38/50], Step [13/32], Loss: 0.4529, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [38/50], Step [14/32], Loss: 0.4114, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [38/50], Step [15/32], Loss: 0.4528, batch time: 0.53, accuracy:  75.00%\n",
      "Epoch [38/50], Step [16/32], Loss: 0.4294, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [38/50], Step [17/32], Loss: 0.3142, batch time: 0.54, accuracy:  88.00%\n",
      "Epoch [38/50], Step [18/32], Loss: 0.3715, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [38/50], Step [19/32], Loss: 0.4709, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [38/50], Step [20/32], Loss: 0.4529, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [38/50], Step [21/32], Loss: 0.4596, batch time: 0.56, accuracy:  80.00%\n",
      "Epoch [38/50], Step [22/32], Loss: 0.4697, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [38/50], Step [23/32], Loss: 0.4037, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [38/50], Step [24/32], Loss: 0.3603, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [38/50], Step [25/32], Loss: 0.4066, batch time: 0.53, accuracy:  80.00%\n",
      "Epoch [38/50], Step [26/32], Loss: 0.3559, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [38/50], Step [27/32], Loss: 0.4539, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [38/50], Step [28/32], Loss: 0.2794, batch time: 0.54, accuracy:  89.00%\n",
      "Epoch [38/50], Step [29/32], Loss: 0.4742, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [38/50], Step [30/32], Loss: 0.4482, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [38/50], Step [31/32], Loss: 0.3596, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [38/50], Step [32/32], Loss: 0.4172, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [39/50], Step [1/32], Loss: 0.4977, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [39/50], Step [2/32], Loss: 0.4600, batch time: 0.57, accuracy:  79.00%\n",
      "Epoch [39/50], Step [3/32], Loss: 0.3190, batch time: 0.64, accuracy:  87.00%\n",
      "Epoch [39/50], Step [4/32], Loss: 0.4714, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [39/50], Step [5/32], Loss: 0.3457, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [39/50], Step [6/32], Loss: 0.4581, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [39/50], Step [7/32], Loss: 0.3685, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [39/50], Step [8/32], Loss: 0.4304, batch time: 0.52, accuracy:  79.00%\n",
      "Epoch [39/50], Step [9/32], Loss: 0.4029, batch time: 0.53, accuracy:  80.00%\n",
      "Epoch [39/50], Step [10/32], Loss: 0.4054, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [39/50], Step [11/32], Loss: 0.3639, batch time: 0.52, accuracy:  86.00%\n",
      "Epoch [39/50], Step [12/32], Loss: 0.3845, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [39/50], Step [13/32], Loss: 0.4808, batch time: 0.52, accuracy:  74.00%\n",
      "Epoch [39/50], Step [14/32], Loss: 0.3441, batch time: 0.51, accuracy:  85.00%\n",
      "Epoch [39/50], Step [15/32], Loss: 0.3537, batch time: 0.53, accuracy:  87.00%\n",
      "Epoch [39/50], Step [16/32], Loss: 0.4133, batch time: 0.52, accuracy:  81.00%\n",
      "Epoch [39/50], Step [17/32], Loss: 0.4041, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [39/50], Step [18/32], Loss: 0.4281, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [39/50], Step [19/32], Loss: 0.3877, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [39/50], Step [20/32], Loss: 0.4301, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [39/50], Step [21/32], Loss: 0.4336, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [39/50], Step [22/32], Loss: 0.3532, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [39/50], Step [23/32], Loss: 0.3435, batch time: 0.52, accuracy:  88.00%\n",
      "Epoch [39/50], Step [24/32], Loss: 0.3951, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [39/50], Step [25/32], Loss: 0.3612, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [39/50], Step [26/32], Loss: 0.4109, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [39/50], Step [27/32], Loss: 0.4005, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [39/50], Step [28/32], Loss: 0.3897, batch time: 0.52, accuracy:  80.00%\n",
      "Epoch [39/50], Step [29/32], Loss: 0.4118, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [39/50], Step [30/32], Loss: 0.3650, batch time: 0.55, accuracy:  89.00%\n",
      "Epoch [39/50], Step [31/32], Loss: 0.5033, batch time: 0.57, accuracy:  80.00%\n",
      "Epoch [39/50], Step [32/32], Loss: 0.4183, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [40/50], Step [1/32], Loss: 0.3455, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [40/50], Step [2/32], Loss: 0.3634, batch time: 0.56, accuracy:  86.00%\n",
      "Epoch [40/50], Step [3/32], Loss: 0.3915, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [40/50], Step [4/32], Loss: 0.4848, batch time: 0.57, accuracy:  82.00%\n",
      "Epoch [40/50], Step [5/32], Loss: 0.3264, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [40/50], Step [6/32], Loss: 0.3681, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [40/50], Step [7/32], Loss: 0.4023, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [40/50], Step [8/32], Loss: 0.3752, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [40/50], Step [9/32], Loss: 0.4645, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [40/50], Step [10/32], Loss: 0.5013, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [40/50], Step [11/32], Loss: 0.2845, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [40/50], Step [12/32], Loss: 0.3393, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [40/50], Step [13/32], Loss: 0.4362, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [40/50], Step [14/32], Loss: 0.4394, batch time: 0.60, accuracy:  84.00%\n",
      "Epoch [40/50], Step [15/32], Loss: 0.5114, batch time: 0.53, accuracy:  79.00%\n",
      "Epoch [40/50], Step [16/32], Loss: 0.4132, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [40/50], Step [17/32], Loss: 0.4070, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [40/50], Step [18/32], Loss: 0.5267, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [40/50], Step [19/32], Loss: 0.3436, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [40/50], Step [20/32], Loss: 0.3895, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [40/50], Step [21/32], Loss: 0.4216, batch time: 0.57, accuracy:  83.00%\n",
      "Epoch [40/50], Step [22/32], Loss: 0.4475, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [40/50], Step [23/32], Loss: 0.3325, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [40/50], Step [24/32], Loss: 0.4105, batch time: 0.53, accuracy:  80.00%\n",
      "Epoch [40/50], Step [25/32], Loss: 0.5479, batch time: 0.52, accuracy:  76.00%\n",
      "Epoch [40/50], Step [26/32], Loss: 0.4342, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [40/50], Step [27/32], Loss: 0.3675, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [40/50], Step [28/32], Loss: 0.3508, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [40/50], Step [29/32], Loss: 0.3933, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [40/50], Step [30/32], Loss: 0.4667, batch time: 0.56, accuracy:  77.00%\n",
      "Epoch [40/50], Step [31/32], Loss: 0.3346, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [40/50], Step [32/32], Loss: 0.3583, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [41/50], Step [1/32], Loss: 0.3637, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [41/50], Step [2/32], Loss: 0.3276, batch time: 0.54, accuracy:  88.00%\n",
      "Epoch [41/50], Step [3/32], Loss: 0.2350, batch time: 0.52, accuracy:  91.00%\n",
      "Epoch [41/50], Step [4/32], Loss: 0.4586, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [41/50], Step [5/32], Loss: 0.4443, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [41/50], Step [6/32], Loss: 0.5059, batch time: 0.57, accuracy:  77.00%\n",
      "Epoch [41/50], Step [7/32], Loss: 0.5015, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [41/50], Step [8/32], Loss: 0.2935, batch time: 0.54, accuracy:  90.00%\n",
      "Epoch [41/50], Step [9/32], Loss: 0.5575, batch time: 0.55, accuracy:  75.00%\n",
      "Epoch [41/50], Step [10/32], Loss: 0.4014, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [41/50], Step [11/32], Loss: 0.3915, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [41/50], Step [12/32], Loss: 0.3593, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [41/50], Step [13/32], Loss: 0.3965, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [41/50], Step [14/32], Loss: 0.5073, batch time: 0.55, accuracy:  77.00%\n",
      "Epoch [41/50], Step [15/32], Loss: 0.3887, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [41/50], Step [16/32], Loss: 0.4443, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [41/50], Step [17/32], Loss: 0.4028, batch time: 0.54, accuracy:  84.00%\n",
      "Epoch [41/50], Step [18/32], Loss: 0.4083, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [41/50], Step [19/32], Loss: 0.4052, batch time: 0.58, accuracy:  89.00%\n",
      "Epoch [41/50], Step [20/32], Loss: 0.5430, batch time: 0.55, accuracy:  74.00%\n",
      "Epoch [41/50], Step [21/32], Loss: 0.3605, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [41/50], Step [22/32], Loss: 0.4360, batch time: 0.52, accuracy:  75.00%\n",
      "Epoch [41/50], Step [23/32], Loss: 0.3665, batch time: 0.56, accuracy:  86.00%\n",
      "Epoch [41/50], Step [24/32], Loss: 0.3752, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [41/50], Step [25/32], Loss: 0.3892, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [41/50], Step [26/32], Loss: 0.4431, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [41/50], Step [27/32], Loss: 0.4136, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [41/50], Step [28/32], Loss: 0.5055, batch time: 0.51, accuracy:  79.00%\n",
      "Epoch [41/50], Step [29/32], Loss: 0.3092, batch time: 0.53, accuracy:  90.00%\n",
      "Epoch [41/50], Step [30/32], Loss: 0.4773, batch time: 0.52, accuracy:  74.00%\n",
      "Epoch [41/50], Step [31/32], Loss: 0.3701, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [41/50], Step [32/32], Loss: 0.3923, batch time: 0.56, accuracy:  84.00%\n",
      "Epoch [42/50], Step [1/32], Loss: 0.4274, batch time: 0.56, accuracy:  85.00%\n",
      "Epoch [42/50], Step [2/32], Loss: 0.3890, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [42/50], Step [3/32], Loss: 0.3524, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [42/50], Step [4/32], Loss: 0.4982, batch time: 0.54, accuracy:  77.00%\n",
      "Epoch [42/50], Step [5/32], Loss: 0.4390, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [42/50], Step [6/32], Loss: 0.4063, batch time: 0.53, accuracy:  80.00%\n",
      "Epoch [42/50], Step [7/32], Loss: 0.3944, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [42/50], Step [8/32], Loss: 0.2794, batch time: 0.55, accuracy:  89.00%\n",
      "Epoch [42/50], Step [9/32], Loss: 0.3610, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [42/50], Step [10/32], Loss: 0.4075, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [42/50], Step [11/32], Loss: 0.4062, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [42/50], Step [12/32], Loss: 0.4035, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [42/50], Step [13/32], Loss: 0.4720, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [42/50], Step [14/32], Loss: 0.4535, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [42/50], Step [15/32], Loss: 0.3940, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [42/50], Step [16/32], Loss: 0.3978, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [42/50], Step [17/32], Loss: 0.4889, batch time: 0.53, accuracy:  75.00%\n",
      "Epoch [42/50], Step [18/32], Loss: 0.4404, batch time: 0.51, accuracy:  79.00%\n",
      "Epoch [42/50], Step [19/32], Loss: 0.4156, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [42/50], Step [20/32], Loss: 0.4138, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [42/50], Step [21/32], Loss: 0.4504, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [42/50], Step [22/32], Loss: 0.4183, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [42/50], Step [23/32], Loss: 0.3409, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [42/50], Step [24/32], Loss: 0.4176, batch time: 0.57, accuracy:  87.00%\n",
      "Epoch [42/50], Step [25/32], Loss: 0.3909, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [42/50], Step [26/32], Loss: 0.3761, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [42/50], Step [27/32], Loss: 0.3741, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [42/50], Step [28/32], Loss: 0.3991, batch time: 0.53, accuracy:  86.00%\n",
      "Epoch [42/50], Step [29/32], Loss: 0.4012, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [42/50], Step [30/32], Loss: 0.3803, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [42/50], Step [31/32], Loss: 0.3198, batch time: 0.57, accuracy:  87.00%\n",
      "Epoch [42/50], Step [32/32], Loss: 0.4147, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [43/50], Step [1/32], Loss: 0.4334, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [43/50], Step [2/32], Loss: 0.4886, batch time: 0.53, accuracy:  78.00%\n",
      "Epoch [43/50], Step [3/32], Loss: 0.4573, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [43/50], Step [4/32], Loss: 0.4548, batch time: 0.57, accuracy:  80.00%\n",
      "Epoch [43/50], Step [5/32], Loss: 0.5126, batch time: 0.54, accuracy:  78.00%\n",
      "Epoch [43/50], Step [6/32], Loss: 0.4664, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [43/50], Step [7/32], Loss: 0.4047, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [43/50], Step [8/32], Loss: 0.4425, batch time: 0.55, accuracy:  77.00%\n",
      "Epoch [43/50], Step [9/32], Loss: 0.4709, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [43/50], Step [10/32], Loss: 0.3922, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [43/50], Step [11/32], Loss: 0.3485, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [43/50], Step [12/32], Loss: 0.4233, batch time: 0.54, accuracy:  85.00%\n",
      "Epoch [43/50], Step [13/32], Loss: 0.4560, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [43/50], Step [14/32], Loss: 0.4026, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [43/50], Step [15/32], Loss: 0.4914, batch time: 0.55, accuracy:  80.00%\n",
      "Epoch [43/50], Step [16/32], Loss: 0.4704, batch time: 0.54, accuracy:  77.00%\n",
      "Epoch [43/50], Step [17/32], Loss: 0.2997, batch time: 0.56, accuracy:  88.00%\n",
      "Epoch [43/50], Step [18/32], Loss: 0.3154, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [43/50], Step [19/32], Loss: 0.3183, batch time: 0.54, accuracy:  86.00%\n",
      "Epoch [43/50], Step [20/32], Loss: 0.3285, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [43/50], Step [21/32], Loss: 0.4262, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [43/50], Step [22/32], Loss: 0.3531, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [43/50], Step [23/32], Loss: 0.4622, batch time: 0.55, accuracy:  81.00%\n",
      "Epoch [43/50], Step [24/32], Loss: 0.3647, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [43/50], Step [25/32], Loss: 0.3551, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [43/50], Step [26/32], Loss: 0.3972, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [43/50], Step [27/32], Loss: 0.3000, batch time: 0.54, accuracy:  89.00%\n",
      "Epoch [43/50], Step [28/32], Loss: 0.3978, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [43/50], Step [29/32], Loss: 0.3706, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [43/50], Step [30/32], Loss: 0.4478, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [43/50], Step [31/32], Loss: 0.2603, batch time: 0.52, accuracy:  91.00%\n",
      "Epoch [43/50], Step [32/32], Loss: 0.4334, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [44/50], Step [1/32], Loss: 0.5211, batch time: 0.54, accuracy:  79.00%\n",
      "Epoch [44/50], Step [2/32], Loss: 0.3819, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [44/50], Step [3/32], Loss: 0.4229, batch time: 0.53, accuracy:  84.00%\n",
      "Epoch [44/50], Step [4/32], Loss: 0.4610, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [44/50], Step [5/32], Loss: 0.4769, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [44/50], Step [6/32], Loss: 0.3454, batch time: 0.55, accuracy:  88.00%\n",
      "Epoch [44/50], Step [7/32], Loss: 0.3124, batch time: 0.52, accuracy:  90.00%\n",
      "Epoch [44/50], Step [8/32], Loss: 0.4271, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [44/50], Step [9/32], Loss: 0.3872, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [44/50], Step [10/32], Loss: 0.4298, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [44/50], Step [11/32], Loss: 0.3924, batch time: 0.52, accuracy:  82.00%\n",
      "Epoch [44/50], Step [12/32], Loss: 0.3370, batch time: 0.55, accuracy:  86.00%\n",
      "Epoch [44/50], Step [13/32], Loss: 0.4142, batch time: 0.52, accuracy:  85.00%\n",
      "Epoch [44/50], Step [14/32], Loss: 0.4724, batch time: 0.52, accuracy:  78.00%\n",
      "Epoch [44/50], Step [15/32], Loss: 0.3429, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [44/50], Step [16/32], Loss: 0.3880, batch time: 0.54, accuracy:  87.00%\n",
      "Epoch [44/50], Step [17/32], Loss: 0.4220, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [44/50], Step [18/32], Loss: 0.5021, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [44/50], Step [19/32], Loss: 0.5344, batch time: 0.55, accuracy:  75.00%\n",
      "Epoch [44/50], Step [20/32], Loss: 0.4817, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [44/50], Step [21/32], Loss: 0.3999, batch time: 0.52, accuracy:  80.00%\n",
      "Epoch [44/50], Step [22/32], Loss: 0.4128, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [44/50], Step [23/32], Loss: 0.4167, batch time: 0.53, accuracy:  83.00%\n",
      "Epoch [44/50], Step [24/32], Loss: 0.3343, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [44/50], Step [25/32], Loss: 0.3161, batch time: 0.54, accuracy:  89.00%\n",
      "Epoch [44/50], Step [26/32], Loss: 0.3884, batch time: 0.55, accuracy:  84.00%\n",
      "Epoch [44/50], Step [27/32], Loss: 0.4279, batch time: 0.55, accuracy:  79.00%\n",
      "Epoch [44/50], Step [28/32], Loss: 0.3402, batch time: 0.56, accuracy:  89.00%\n",
      "Epoch [44/50], Step [29/32], Loss: 0.4372, batch time: 0.56, accuracy:  82.00%\n",
      "Epoch [44/50], Step [30/32], Loss: 0.5372, batch time: 0.54, accuracy:  77.00%\n",
      "Epoch [44/50], Step [31/32], Loss: 0.3396, batch time: 0.55, accuracy:  90.00%\n",
      "Epoch [44/50], Step [32/32], Loss: 0.2723, batch time: 0.62, accuracy:  88.00%\n",
      "Epoch [45/50], Step [1/32], Loss: 0.4279, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [45/50], Step [2/32], Loss: 0.4168, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [45/50], Step [3/32], Loss: 0.3802, batch time: 0.52, accuracy:  83.00%\n",
      "Epoch [45/50], Step [4/32], Loss: 0.5278, batch time: 0.56, accuracy:  75.00%\n",
      "Epoch [45/50], Step [5/32], Loss: 0.3828, batch time: 0.57, accuracy:  88.00%\n",
      "Epoch [45/50], Step [6/32], Loss: 0.4232, batch time: 0.83, accuracy:  79.00%\n",
      "Epoch [45/50], Step [7/32], Loss: 0.4411, batch time: 0.85, accuracy:  83.00%\n",
      "Epoch [45/50], Step [8/32], Loss: 0.4016, batch time: 0.57, accuracy:  84.00%\n",
      "Epoch [45/50], Step [9/32], Loss: 0.4517, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [45/50], Step [10/32], Loss: 0.3717, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [45/50], Step [11/32], Loss: 0.4592, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [45/50], Step [12/32], Loss: 0.4186, batch time: 0.57, accuracy:  83.00%\n",
      "Epoch [45/50], Step [13/32], Loss: 0.4814, batch time: 0.56, accuracy:  83.00%\n",
      "Epoch [45/50], Step [14/32], Loss: 0.4232, batch time: 0.54, accuracy:  80.00%\n",
      "Epoch [45/50], Step [15/32], Loss: 0.4012, batch time: 0.52, accuracy:  84.00%\n",
      "Epoch [45/50], Step [16/32], Loss: 0.3633, batch time: 0.56, accuracy:  87.00%\n",
      "Epoch [45/50], Step [17/32], Loss: 0.3154, batch time: 0.52, accuracy:  90.00%\n",
      "Epoch [45/50], Step [18/32], Loss: 0.3949, batch time: 0.55, accuracy:  82.00%\n",
      "Epoch [45/50], Step [19/32], Loss: 0.4543, batch time: 0.55, accuracy:  78.00%\n",
      "Epoch [45/50], Step [20/32], Loss: 0.4648, batch time: 0.57, accuracy:  82.00%\n",
      "Epoch [45/50], Step [21/32], Loss: 0.3856, batch time: 0.54, accuracy:  83.00%\n",
      "Epoch [45/50], Step [22/32], Loss: 0.3463, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [45/50], Step [23/32], Loss: 0.3822, batch time: 0.53, accuracy:  85.00%\n",
      "Epoch [45/50], Step [24/32], Loss: 0.3590, batch time: 0.52, accuracy:  88.00%\n",
      "Epoch [45/50], Step [25/32], Loss: 0.4265, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [45/50], Step [26/32], Loss: 0.4932, batch time: 0.53, accuracy:  77.00%\n",
      "Epoch [45/50], Step [27/32], Loss: 0.4474, batch time: 0.53, accuracy:  82.00%\n",
      "Epoch [45/50], Step [28/32], Loss: 0.4139, batch time: 0.56, accuracy:  86.00%\n",
      "Epoch [45/50], Step [29/32], Loss: 0.3717, batch time: 0.53, accuracy:  88.00%\n",
      "Epoch [45/50], Step [30/32], Loss: 0.3773, batch time: 0.65, accuracy:  84.00%\n",
      "Epoch [45/50], Step [31/32], Loss: 0.2875, batch time: 0.56, accuracy:  90.00%\n",
      "Epoch [45/50], Step [32/32], Loss: 0.2870, batch time: 0.58, accuracy:  93.00%\n",
      "Epoch [46/50], Step [1/32], Loss: 0.4498, batch time: 0.56, accuracy:  81.00%\n",
      "Epoch [46/50], Step [2/32], Loss: 0.4635, batch time: 0.53, accuracy:  81.00%\n",
      "Epoch [46/50], Step [3/32], Loss: 0.4320, batch time: 0.54, accuracy:  82.00%\n",
      "Epoch [46/50], Step [4/32], Loss: 0.4775, batch time: 0.57, accuracy:  78.00%\n",
      "Epoch [46/50], Step [5/32], Loss: 0.5092, batch time: 0.55, accuracy:  76.00%\n",
      "Epoch [46/50], Step [6/32], Loss: 0.4093, batch time: 0.68, accuracy:  81.00%\n",
      "Epoch [46/50], Step [7/32], Loss: 0.4626, batch time: 0.56, accuracy:  79.00%\n",
      "Epoch [46/50], Step [8/32], Loss: 0.3517, batch time: 0.55, accuracy:  83.00%\n",
      "Epoch [46/50], Step [9/32], Loss: 0.3932, batch time: 0.57, accuracy:  87.00%\n",
      "Epoch [46/50], Step [10/32], Loss: 0.3653, batch time: 0.55, accuracy:  85.00%\n",
      "Epoch [46/50], Step [11/32], Loss: 0.4019, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [46/50], Step [12/32], Loss: 0.3380, batch time: 0.53, accuracy:  88.00%\n",
      "Epoch [46/50], Step [13/32], Loss: 0.4281, batch time: 0.54, accuracy:  81.00%\n",
      "Epoch [46/50], Step [14/32], Loss: 0.3780, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [46/50], Step [15/32], Loss: 0.3651, batch time: 0.71, accuracy:  80.00%\n",
      "Epoch [46/50], Step [16/32], Loss: 0.3676, batch time: 0.68, accuracy:  87.00%\n",
      "Epoch [46/50], Step [17/32], Loss: 0.3792, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [46/50], Step [18/32], Loss: 0.4217, batch time: 0.56, accuracy:  78.00%\n",
      "Epoch [46/50], Step [19/32], Loss: 0.3199, batch time: 0.64, accuracy:  88.00%\n",
      "Epoch [46/50], Step [20/32], Loss: 0.3665, batch time: 0.59, accuracy:  86.00%\n",
      "Epoch [46/50], Step [21/32], Loss: 0.3596, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [46/50], Step [22/32], Loss: 0.4377, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [46/50], Step [23/32], Loss: 0.4012, batch time: 0.58, accuracy:  83.00%\n",
      "Epoch [46/50], Step [24/32], Loss: 0.5389, batch time: 0.59, accuracy:  73.00%\n",
      "Epoch [46/50], Step [25/32], Loss: 0.4227, batch time: 0.63, accuracy:  83.00%\n",
      "Epoch [46/50], Step [26/32], Loss: 0.3586, batch time: 0.60, accuracy:  91.00%\n",
      "Epoch [46/50], Step [27/32], Loss: 0.4139, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [46/50], Step [28/32], Loss: 0.4455, batch time: 0.72, accuracy:  80.00%\n",
      "Epoch [46/50], Step [29/32], Loss: 0.4036, batch time: 0.58, accuracy:  86.00%\n",
      "Epoch [46/50], Step [30/32], Loss: 0.4653, batch time: 0.59, accuracy:  77.00%\n",
      "Epoch [46/50], Step [31/32], Loss: 0.2577, batch time: 0.59, accuracy:  91.00%\n",
      "Epoch [46/50], Step [32/32], Loss: 0.3944, batch time: 0.58, accuracy:  84.00%\n",
      "Epoch [47/50], Step [1/32], Loss: 0.3283, batch time: 0.60, accuracy:  89.00%\n",
      "Epoch [47/50], Step [2/32], Loss: 0.4021, batch time: 0.61, accuracy:  82.00%\n",
      "Epoch [47/50], Step [3/32], Loss: 0.3775, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [47/50], Step [4/32], Loss: 0.3787, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [47/50], Step [5/32], Loss: 0.4446, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [47/50], Step [6/32], Loss: 0.3916, batch time: 0.59, accuracy:  84.00%\n",
      "Epoch [47/50], Step [7/32], Loss: 0.3967, batch time: 0.64, accuracy:  82.00%\n",
      "Epoch [47/50], Step [8/32], Loss: 0.3775, batch time: 0.66, accuracy:  87.00%\n",
      "Epoch [47/50], Step [9/32], Loss: 0.4253, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [47/50], Step [10/32], Loss: 0.4134, batch time: 0.61, accuracy:  84.00%\n",
      "Epoch [47/50], Step [11/32], Loss: 0.3343, batch time: 0.62, accuracy:  86.00%\n",
      "Epoch [47/50], Step [12/32], Loss: 0.3123, batch time: 0.65, accuracy:  94.00%\n",
      "Epoch [47/50], Step [13/32], Loss: 0.4572, batch time: 0.62, accuracy:  77.00%\n",
      "Epoch [47/50], Step [14/32], Loss: 0.3965, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [47/50], Step [15/32], Loss: 0.3695, batch time: 0.64, accuracy:  83.00%\n",
      "Epoch [47/50], Step [16/32], Loss: 0.4019, batch time: 0.62, accuracy:  82.00%\n",
      "Epoch [47/50], Step [17/32], Loss: 0.4916, batch time: 0.61, accuracy:  75.00%\n",
      "Epoch [47/50], Step [18/32], Loss: 0.4839, batch time: 0.63, accuracy:  78.00%\n",
      "Epoch [47/50], Step [19/32], Loss: 0.3637, batch time: 0.60, accuracy:  88.00%\n",
      "Epoch [47/50], Step [20/32], Loss: 0.4131, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [47/50], Step [21/32], Loss: 0.4184, batch time: 0.67, accuracy:  80.00%\n",
      "Epoch [47/50], Step [22/32], Loss: 0.4751, batch time: 0.74, accuracy:  81.00%\n",
      "Epoch [47/50], Step [23/32], Loss: 0.3666, batch time: 0.73, accuracy:  85.00%\n",
      "Epoch [47/50], Step [24/32], Loss: 0.3163, batch time: 0.81, accuracy:  88.00%\n",
      "Epoch [47/50], Step [25/32], Loss: 0.4211, batch time: 0.79, accuracy:  80.00%\n",
      "Epoch [47/50], Step [26/32], Loss: 0.4558, batch time: 0.84, accuracy:  84.00%\n",
      "Epoch [47/50], Step [27/32], Loss: 0.4358, batch time: 0.87, accuracy:  84.00%\n",
      "Epoch [47/50], Step [28/32], Loss: 0.5122, batch time: 0.66, accuracy:  78.00%\n",
      "Epoch [47/50], Step [29/32], Loss: 0.4543, batch time: 0.82, accuracy:  82.00%\n",
      "Epoch [47/50], Step [30/32], Loss: 0.4344, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [47/50], Step [31/32], Loss: 0.3329, batch time: 0.58, accuracy:  84.00%\n",
      "Epoch [47/50], Step [32/32], Loss: 0.4023, batch time: 0.59, accuracy:  78.00%\n",
      "Epoch [48/50], Step [1/32], Loss: 0.4194, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [48/50], Step [2/32], Loss: 0.3698, batch time: 0.63, accuracy:  80.00%\n",
      "Epoch [48/50], Step [3/32], Loss: 0.3801, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [48/50], Step [4/32], Loss: 0.5079, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [48/50], Step [5/32], Loss: 0.4000, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [48/50], Step [6/32], Loss: 0.3946, batch time: 0.65, accuracy:  83.00%\n",
      "Epoch [48/50], Step [7/32], Loss: 0.5102, batch time: 0.60, accuracy:  79.00%\n",
      "Epoch [48/50], Step [8/32], Loss: 0.3446, batch time: 0.55, accuracy:  87.00%\n",
      "Epoch [48/50], Step [9/32], Loss: 0.5198, batch time: 0.58, accuracy:  79.00%\n",
      "Epoch [48/50], Step [10/32], Loss: 0.4523, batch time: 0.61, accuracy:  77.00%\n",
      "Epoch [48/50], Step [11/32], Loss: 0.3254, batch time: 0.65, accuracy:  90.00%\n",
      "Epoch [48/50], Step [12/32], Loss: 0.4255, batch time: 0.62, accuracy:  84.00%\n",
      "Epoch [48/50], Step [13/32], Loss: 0.4134, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [48/50], Step [14/32], Loss: 0.4197, batch time: 0.69, accuracy:  80.00%\n",
      "Epoch [48/50], Step [15/32], Loss: 0.4790, batch time: 0.58, accuracy:  80.00%\n",
      "Epoch [48/50], Step [16/32], Loss: 0.3544, batch time: 0.65, accuracy:  88.00%\n",
      "Epoch [48/50], Step [17/32], Loss: 0.4121, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [48/50], Step [18/32], Loss: 0.3693, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [48/50], Step [19/32], Loss: 0.3237, batch time: 0.82, accuracy:  88.00%\n",
      "Epoch [48/50], Step [20/32], Loss: 0.3815, batch time: 0.86, accuracy:  87.00%\n",
      "Epoch [48/50], Step [21/32], Loss: 0.3321, batch time: 0.82, accuracy:  87.00%\n",
      "Epoch [48/50], Step [22/32], Loss: 0.5069, batch time: 0.65, accuracy:  75.00%\n",
      "Epoch [48/50], Step [23/32], Loss: 0.3179, batch time: 0.64, accuracy:  89.00%\n",
      "Epoch [48/50], Step [24/32], Loss: 0.4700, batch time: 0.62, accuracy:  76.00%\n",
      "Epoch [48/50], Step [25/32], Loss: 0.4970, batch time: 0.72, accuracy:  80.00%\n",
      "Epoch [48/50], Step [26/32], Loss: 0.3445, batch time: 0.70, accuracy:  85.00%\n",
      "Epoch [48/50], Step [27/32], Loss: 0.3245, batch time: 0.61, accuracy:  88.00%\n",
      "Epoch [48/50], Step [28/32], Loss: 0.4072, batch time: 0.57, accuracy:  81.00%\n",
      "Epoch [48/50], Step [29/32], Loss: 0.3828, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [48/50], Step [30/32], Loss: 0.4192, batch time: 0.67, accuracy:  84.00%\n",
      "Epoch [48/50], Step [31/32], Loss: 0.3844, batch time: 0.62, accuracy:  89.00%\n",
      "Epoch [48/50], Step [32/32], Loss: 0.3149, batch time: 0.63, accuracy:  91.00%\n",
      "Epoch [49/50], Step [1/32], Loss: 0.4716, batch time: 0.66, accuracy:  79.00%\n",
      "Epoch [49/50], Step [2/32], Loss: 0.3703, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [49/50], Step [3/32], Loss: 0.5231, batch time: 0.62, accuracy:  78.00%\n",
      "Epoch [49/50], Step [4/32], Loss: 0.4283, batch time: 0.69, accuracy:  83.00%\n",
      "Epoch [49/50], Step [5/32], Loss: 0.4344, batch time: 0.67, accuracy:  79.00%\n",
      "Epoch [49/50], Step [6/32], Loss: 0.4080, batch time: 0.58, accuracy:  81.00%\n",
      "Epoch [49/50], Step [7/32], Loss: 0.4341, batch time: 0.64, accuracy:  80.00%\n",
      "Epoch [49/50], Step [8/32], Loss: 0.3134, batch time: 0.73, accuracy:  90.00%\n",
      "Epoch [49/50], Step [9/32], Loss: 0.3653, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [49/50], Step [10/32], Loss: 0.3677, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [49/50], Step [11/32], Loss: 0.3397, batch time: 0.65, accuracy:  87.00%\n",
      "Epoch [49/50], Step [12/32], Loss: 0.3257, batch time: 0.65, accuracy:  86.00%\n",
      "Epoch [49/50], Step [13/32], Loss: 0.4382, batch time: 0.65, accuracy:  80.00%\n",
      "Epoch [49/50], Step [14/32], Loss: 0.4648, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [49/50], Step [15/32], Loss: 0.4705, batch time: 0.62, accuracy:  81.00%\n",
      "Epoch [49/50], Step [16/32], Loss: 0.3684, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [49/50], Step [17/32], Loss: 0.4099, batch time: 0.60, accuracy:  80.00%\n",
      "Epoch [49/50], Step [18/32], Loss: 0.3312, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [49/50], Step [19/32], Loss: 0.3842, batch time: 0.65, accuracy:  82.00%\n",
      "Epoch [49/50], Step [20/32], Loss: 0.4611, batch time: 0.61, accuracy:  78.00%\n",
      "Epoch [49/50], Step [21/32], Loss: 0.3897, batch time: 0.69, accuracy:  84.00%\n",
      "Epoch [49/50], Step [22/32], Loss: 0.3721, batch time: 0.70, accuracy:  82.00%\n",
      "Epoch [49/50], Step [23/32], Loss: 0.4549, batch time: 0.73, accuracy:  82.00%\n",
      "Epoch [49/50], Step [24/32], Loss: 0.4067, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [49/50], Step [25/32], Loss: 0.4953, batch time: 0.66, accuracy:  77.00%\n",
      "Epoch [49/50], Step [26/32], Loss: 0.3560, batch time: 0.64, accuracy:  84.00%\n",
      "Epoch [49/50], Step [27/32], Loss: 0.4910, batch time: 0.65, accuracy:  76.00%\n",
      "Epoch [49/50], Step [28/32], Loss: 0.3523, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [49/50], Step [29/32], Loss: 0.3416, batch time: 0.64, accuracy:  88.00%\n",
      "Epoch [49/50], Step [30/32], Loss: 0.3508, batch time: 0.63, accuracy:  90.00%\n",
      "Epoch [49/50], Step [31/32], Loss: 0.3899, batch time: 0.58, accuracy:  85.00%\n",
      "Epoch [49/50], Step [32/32], Loss: 0.4429, batch time: 0.60, accuracy:  81.00%\n",
      "Epoch [50/50], Step [1/32], Loss: 0.3750, batch time: 0.70, accuracy:  84.00%\n",
      "Epoch [50/50], Step [2/32], Loss: 0.3933, batch time: 0.65, accuracy:  85.00%\n",
      "Epoch [50/50], Step [3/32], Loss: 0.4798, batch time: 0.61, accuracy:  81.00%\n",
      "Epoch [50/50], Step [4/32], Loss: 0.4482, batch time: 0.60, accuracy:  83.00%\n",
      "Epoch [50/50], Step [5/32], Loss: 0.5724, batch time: 0.60, accuracy:  72.00%\n",
      "Epoch [50/50], Step [6/32], Loss: 0.4420, batch time: 0.58, accuracy:  80.00%\n",
      "Epoch [50/50], Step [7/32], Loss: 0.5006, batch time: 0.66, accuracy:  76.00%\n",
      "Epoch [50/50], Step [8/32], Loss: 0.3720, batch time: 0.69, accuracy:  82.00%\n",
      "Epoch [50/50], Step [9/32], Loss: 0.3767, batch time: 0.63, accuracy:  86.00%\n",
      "Epoch [50/50], Step [10/32], Loss: 0.4437, batch time: 0.63, accuracy:  82.00%\n",
      "Epoch [50/50], Step [11/32], Loss: 0.3540, batch time: 0.63, accuracy:  85.00%\n",
      "Epoch [50/50], Step [12/32], Loss: 0.3125, batch time: 0.63, accuracy:  89.00%\n",
      "Epoch [50/50], Step [13/32], Loss: 0.3185, batch time: 0.71, accuracy:  88.00%\n",
      "Epoch [50/50], Step [14/32], Loss: 0.4072, batch time: 0.68, accuracy:  85.00%\n",
      "Epoch [50/50], Step [15/32], Loss: 0.2908, batch time: 0.62, accuracy:  87.00%\n",
      "Epoch [50/50], Step [16/32], Loss: 0.4444, batch time: 0.61, accuracy:  83.00%\n",
      "Epoch [50/50], Step [17/32], Loss: 0.3371, batch time: 0.68, accuracy:  89.00%\n",
      "Epoch [50/50], Step [18/32], Loss: 0.5717, batch time: 0.76, accuracy:  77.00%\n",
      "Epoch [50/50], Step [19/32], Loss: 0.3682, batch time: 0.78, accuracy:  83.00%\n",
      "Epoch [50/50], Step [20/32], Loss: 0.3198, batch time: 0.58, accuracy:  88.00%\n",
      "Epoch [50/50], Step [21/32], Loss: 0.4258, batch time: 0.71, accuracy:  82.00%\n",
      "Epoch [50/50], Step [22/32], Loss: 0.5914, batch time: 0.61, accuracy:  74.00%\n",
      "Epoch [50/50], Step [23/32], Loss: 0.3130, batch time: 0.63, accuracy:  87.00%\n",
      "Epoch [50/50], Step [24/32], Loss: 0.3736, batch time: 0.61, accuracy:  85.00%\n",
      "Epoch [50/50], Step [25/32], Loss: 0.3800, batch time: 0.60, accuracy:  82.00%\n",
      "Epoch [50/50], Step [26/32], Loss: 0.4484, batch time: 0.63, accuracy:  84.00%\n",
      "Epoch [50/50], Step [27/32], Loss: 0.3760, batch time: 0.60, accuracy:  85.00%\n",
      "Epoch [50/50], Step [28/32], Loss: 0.3433, batch time: 0.60, accuracy:  86.00%\n",
      "Epoch [50/50], Step [29/32], Loss: 0.5467, batch time: 0.61, accuracy:  74.00%\n",
      "Epoch [50/50], Step [30/32], Loss: 0.3067, batch time: 0.59, accuracy:  89.00%\n",
      "Epoch [50/50], Step [31/32], Loss: 0.3669, batch time: 0.62, accuracy:  83.00%\n",
      "Epoch [50/50], Step [32/32], Loss: 0.3474, batch time: 0.58, accuracy:  83.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # print(\"output: \", outputs)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=2).float()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "        np.array(loss_list).dump(\"result/TFIM_1x16/L16/loss_list.dat\")\n",
    "        np.array(acc_list).dump(\"result/TFIM_1x16/L16/acc_list.dat\")\n",
    "        if acc > acc_best:\n",
    "            torch.save(model, 'result/TFIM_1x16/L16/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "            acc_best = acc\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if (i+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 82.44%\n",
      "Loss on the train set: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 85.50%\n",
      "Loss on the test set: 0.38\n",
      "Generalization error: -0.03983146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 85.50%\n",
      "Loss on the test set: 0.38\n",
      "Generalization error: -0.039831459522247314\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "# Initialize lists to store indices or minimal information for correct and incorrect predictions\n",
    "correct_predictions = []\n",
    "incorrect_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update correct and incorrect lists\n",
    "        matches = predicted == labels\n",
    "        for j, match in enumerate(matches):\n",
    "            if match:\n",
    "                correct_predictions.append((i, j))  # Store tuple of (batch_index, sample_index) for correct predictions\n",
    "            else:\n",
    "                incorrect_predictions.append((i, j))  # Store tuple of (batch_index, sample_index) for incorrect predictions\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "mean_loss_test = np.mean(loss_test_list)\n",
    "generalization_error = mean_loss_test - np.mean(loss_train_list)  # Assuming loss_train_list is defined elsewhere\n",
    "\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "print(f\"Loss on the test set: {mean_loss_test:.2f}\")\n",
    "print(f\"Generalization error: {generalization_error}\")\n",
    "\n",
    "# Now you have `correct_predictions` and `incorrect_predictions` lists with indices to reference the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
